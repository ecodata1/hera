[{"path":"https://ecodata1.github.io/hera/articles/bankside-consistency.html","id":"welcome","dir":"Articles","previous_headings":"","what":"Welcome","title":"Bankside Consistency","text":"document created following generic assessment guidance. Rapid Assessment Technique (RAT) results bankside invertebrates analysis check consistency Water Body Status.","code":""},{"path":"https://ecodata1.github.io/hera/articles/bankside-consistency.html","id":"description","dir":"Articles","previous_headings":"","what":"Description","title":"Bankside Consistency","text":"Basic details assessment. Update ‘response’ values required.","code":""},{"path":"https://ecodata1.github.io/hera/articles/bankside-consistency.html","id":"input","dir":"Articles","previous_headings":"","what":"Input","title":"Bankside Consistency","text":"list questions required run assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/bankside-consistency.html","id":"assessment","dir":"Articles","previous_headings":"","what":"Assessment","title":"Bankside Consistency","text":"applicable, write function assess input data return outcome. example, metric, statistic, prediction etc. ​ Code","code":"assessment_function <- function(data) {   # Some calculated a statistic...   # Note, any non-standard base R library must be call using require().   require(dplyr)   require(tidyr)   require(magrittr)   require(tibble)   require(whpt)   require(macroinvertebrateMetrics)   data$date_taken <- as.character(format.Date(data$date_taken, \"%Y/%m/%d\"))   catalogue <- hera::catalogue   metric_function <- catalogue[catalogue$assessment ==     \"Macroinvertebrate Metrics\", 3][[1]]   output <- metric_function[[1]](data)   output <- filter(output, question %in% c(\"WHPT_ASPT\", \"WHPT_NTAXA\"))   predictors <- utils::read.csv(system.file(\"extdat\",     \"predictors.csv\",     package = \"whpt\"   ), check.names = FALSE)   predictors$location_id <- as.character(predictors$location_id)   predict_data <- filter(predictors, location_id %in% unique(data$location_id))   output_location <- inner_join(output,     data[, c(       \"location_id\",       \"sample_id\",       \"date_taken\"     )],     by = \"sample_id\",     relationship = \"many-to-many\"   )   output_location$location_id <-     as.character(output_location$location_id)   whpt_input <- inner_join(output_location,     predict_data,     by = \"location_id\"   )   whpt_input$question[whpt_input$question == \"WHPT_ASPT\"] <-     \"WHPT ASPT Abund\"   whpt_input$question[whpt_input$question == \"WHPT_NTAXA\"] <-     \"WHPT NTAXA Abund\"   if (nrow(whpt_input) < 1) {     return(NULL)   } else {     whpt_input <- unique(whpt_input)     whpt_input$response <- as.numeric(whpt_input$response)     consistency_check <- whpt::whpts(whpt_input)     consistency_check$response <-       as.character(consistency_check$response)   }  report <- tidyr::pivot_wider(consistency_check, names_from = question, values_from = response) vars <- c(\"location_id\", \"location_description\", \"sample_id\", \"date_taken\") location_ids <- dplyr::select(data, any_of(vars)) %>%  unique() location_ids$season <- hera:::season(location_ids$date_taken, output = \"shortname\") report <- inner_join(report, location_ids, by = join_by(sample_id))  new_predictors <- read.csv(   system.file(\"extdat\", \"predictors.csv\", package = \"whpt\"),   check.names = FALSE)  report <- dplyr::inner_join(report, new_predictors, by = join_by(location_id))  whpt_wide <- tidyr::pivot_wider(output, names_from = question, values_from = response) report <- dplyr::inner_join(report, whpt_wide, by = join_by(sample_id))  vars <- c( \"water body sampled\", \"sample_id\",  \"date_taken\", \"location_id\", \"location_description\", \"season\", \"Reference NTAXA\", \"Reference ASPT\",  \"assessment\", \"driver\",  \"WHPT_NTAXA\", \"WHPT_ASPT\", \"Typical ASPT Class\", \"Typical NTAXA Class\", \"Reported WHPT Class Year\" )   report <- dplyr::select(report, any_of(vars)) vars <- c( \"season\", \"Reference NTAXA\", \"Reference ASPT\",  \"assessment\", \"driver\",  \"WHPT_NTAXA\", \"WHPT_ASPT\", \"Typical ASPT Class\", \"Typical NTAXA Class\", \"Reported WHPT Class Year\", \"water body sampled\" ) report$`water body sampled` <- as.character(report$`water body sampled`) consistency_check <- pivot_longer(report, cols = all_of(vars), names_to = \"question\", values_to = \"response\")  consistency_check$date_taken <- as.Date(consistency_check$date_taken)   consistency_check$parameter <- \"Bankside Consistency\"   return(consistency_check) }"},{"path":"https://ecodata1.github.io/hera/articles/bankside-consistency.html","id":"outcome","dir":"Articles","previous_headings":"","what":"Outcome","title":"Bankside Consistency","text":"outcome assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/bankside-consistency.html","id":"check","dir":"Articles","previous_headings":"","what":"Check","title":"Bankside Consistency","text":"Run checks assessment.","code":"#> Test passed  #> Test passed"},{"path":"https://ecodata1.github.io/hera/articles/bankside-consistency.html","id":"update","dir":"Articles","previous_headings":"","what":"Update","title":"Bankside Consistency","text":"Update catalogue assessments make available. updating catalogue, rebuild package, click Build > Install Restart menu ‘Install Restart’ button Build pane.","code":""},{"path":"https://ecodata1.github.io/hera/articles/bankside-consistency.html","id":"test","dir":"Articles","previous_headings":"","what":"Test","title":"Bankside Consistency","text":"section tests assessment usable using assess function. Using demo data: Using converted data:","code":""},{"path":"https://ecodata1.github.io/hera/articles/bankside-consistency.html","id":"launch-app","dir":"Articles","previous_headings":"","what":"Launch app","title":"Bankside Consistency","text":"interactive application displaying results assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/darleq3.html","id":"welcome","dir":"Articles","previous_headings":"","what":"Welcome","title":"DARLEQ3","text":"document created following generic assessment guidance.","code":""},{"path":"https://ecodata1.github.io/hera/articles/darleq3.html","id":"description","dir":"Articles","previous_headings":"","what":"Description","title":"DARLEQ3","text":"Basic details assessment. Update ‘response’ values required.","code":""},{"path":"https://ecodata1.github.io/hera/articles/darleq3.html","id":"input","dir":"Articles","previous_headings":"","what":"Input","title":"DARLEQ3","text":"list questions required run assessment.","code":"#> # A tibble: 8 × 9 #>   question   response label parameter data_type max   min   source question_type #>   <chr>      <chr>    <chr> <chr>     <chr>     <lgl> <lgl> <chr>  <chr>         #> 1 location_… 8175     Gomp… NA        character NA    NA    sepa_… reference     #> 2 sample_id  1        NA    NA        character NA    NA    sepa_… reference     #> 3 date_taken 2021-05… NA    NA        character NA    NA    sepa_… reference     #> 4 Taxon abu… 12       NA    NA        number    NA    NA    sepa_… observation   #> 5 parameter  45       NA    NA        number    NA    NA    locat… reference     #> 6 Alkalinity River D… NA    River Di… character NA    NA    sepa_… predictor     #> 7 TDI4       45       NA    NA        number    NA    NA    sepa_… outcome       #> 8 Predicted… 67       NA    NA        number    NA    NA    sepa_… outcome"},{"path":"https://ecodata1.github.io/hera/articles/darleq3.html","id":"assessment","dir":"Articles","previous_headings":"","what":"Assessment","title":"DARLEQ3","text":"applicable, write function assess input data return outcome. example, metric, statistic, prediction etc.","code":"assessment_function <- function(data) {   require(dplyr)   require(tidyr)   require(magrittr)   require(tibble)    # Get alkalinity predictor if not present...   if (!any(names(data) %in% \"alkalinity\")) {     # predictor table for alkalinity if \"chemistry_site\" variable     predictors <- utils::read.csv(       system.file(\"extdat\",         \"predictors.csv\",         package = \"hera\"       ),       stringsAsFactors = FALSE, check.names = FALSE     )     predictors$location_id <- as.character(predictors$location_id)     if (!any(names(data) %in% \"chemistry_site\")) {       data <- left_join(data, predictors, by = c(\"location_id\"))     }      if (!any(names(data) %in% c(\"alkalinity\"))) {       message(\"calculating alklainity...\")       alk <- hera:::mean_alkalinity(data)       data$alkalinity <- NULL       data <- inner_join(data, alk, by = join_by(\"sample_id\" == \"sample_number\"))     }   }   data <- filter(data, question == \"Taxon abundance\" &     parameter == \"River Diatoms\")   data$response <- as.numeric(data$response)   data$alkalinity[is.na(data$alkalinity)] <- 75    data$alkalinity <- as.numeric(data$alkalinity)   # Combine mean alkalinity with other site headers   header <- data %>%     mutate(       \"SampleID\" = as.factor(sample_id),       \"DATE_TAKEN\" = as.Date(date_taken, tz = \"GB\")     ) %>%     select(\"SampleID\",       \"SiteID\" = \"location_id\",       \"SAMPLE_DATE\" = \"date_taken\",       \"Alkalinity\" = \"alkalinity\"     ) %>%     unique()    # Loch samples also require an Alkalinity 'type';   # 'HA' - High Alkalninty etc   # This will be ignored if running river classification   header$lake_TYPE <- NA   header$lake_TYPE[header$Alkalinity > 50] <- \"HA\"   header$lake_TYPE[header$Alkalinity >= 10 &     header$Alkalinity <= 50] <- \"MA\"   header$lake_TYPE[header$Alkalinity < 10] <- \"LA\"    header$SiteID <- as.character(header$SiteID)   ## Important: Arrange to match order of 'diatom_data' data frame.   header <- arrange(header, SampleID)    # Prepare dataframe of 'diatom_data' -------------------------------   # Include columns for each diatom ID (from NEMS Dares table)   # responses are abundances.   # dataframe row.names are SAMPLE_NUMBER.    # DARES table   # - must use table from NEMS - this links TAXON to TAXONLD code   dares_table <- darleq3::darleq3_taxa   # Filter for taxon abundance only   diatom_taxon_abundance <- data %>%     filter(question == \"taxon abundance\" |       question == \"Taxon abundance\")    # Trim whitespace in Taxon name to help join.   diatom_taxon_abundance$label <- trimws(diatom_taxon_abundance$label)   dares_table$TaxonNameSEPA <- trimws(dares_table$TaxonNameSEPA)   # Join to S_TAXON_DARES table using Taxon name.   if (any(names(diatom_taxon_abundance) %in% c(\"taxon_ids\"))) {     diatom_taxonname <- diatom_taxon_abundance %>%       select(         \"location_id\",         \"sample_id\",         \"taxon_ids\",         \"label\",         \"response\",         \"date_taken\"       ) %>%       inner_join(dares_table[, c(\"TaxonName\", \"TaxonId\", \"TaxonNameSEPA\")],         by = c(\"taxon_ids\" = \"TaxonId\")       )     diatom_taxonname$TaxonId <- diatom_taxonname$taxon_ids   } else {     diatom_taxonname <- diatom_taxon_abundance %>%       select(         \"location_id\",         \"sample_id\",         \"label\",         \"response\",         \"date_taken\"       ) %>%       inner_join(dares_table[, c(\"TaxonName\", \"TaxonId\", \"TaxonNameSEPA\")],         by = c(\"label\" = \"TaxonNameSEPA\")       )   }   # Make sure numeric   diatom_taxonname$response <-     as.numeric(as.character(diatom_taxonname$response))   # Sum response if duplicate taxon names entered within a single sample   diatom_tidied <- diatom_taxonname %>%     group_by(sample_id, TaxonId, label, date_taken) %>%     summarise(response = sum(response, na.rm = TRUE), .groups = \"drop\")    # Arrange to keep in same order as 'taxon_names' data.frame   diatom_tidied <- diatom_tidied %>%     ungroup() %>%     arrange(label) %>%     select(-\"label\")    # DARLEQ3 requires Taxon IDs and responses pivoted into wide format   diatom_data <- diatom_tidied %>% pivot_wider(     names_from = TaxonId,     values_from = response,   )   diatom_data[is.na(diatom_data)] <- 0     # Arrange by sampled_date to match order of 'header' data frame.   diatom_data <- arrange(diatom_data, sample_id)   # darleq3 requires row.names equal SAMPLE_NUMBER. Must convert   # to be data.frame first (row.names deprecated on tibble).   diatom_data <- data.frame(diatom_data, check.names = FALSE)   row.names(diatom_data) <- diatom_data$sample_id   diatom_data <- select(diatom_data, -\"sample_id\", -\"date_taken\")    # Prepare dataframe of 'taxon_names'  ------------------------------   # include columns 'TaxonCode','TaxonName'   taxon_names <- diatom_taxonname %>%     select(       \"TaxonCode\" = \"TaxonId\",       \"TaxonName\" = \"TaxonName\"     ) %>%     unique()   taxon_names <- arrange(taxon_names, TaxonName)    # Combine dataframes into named list ------------------------   header <- data.frame(header)   header <- header[header$SampleID %in% row.names(diatom_data), ]   header <- header[!duplicated(header$SampleID), ]   row.names(header) <- header$SampleID   header$SampleID <- as.character(header$SampleID)   header$SAMPLE_DATE <- as.Date(header$SAMPLE_DATE)   output <- darleq3::calc_Metric(diatom_data, metric = \"TDI4\")   output <- darleq3::calc_EQR(output,     header,     truncate_EQR = TRUE,     verbose = TRUE   )    sample <- output$EQR   sample <- sample %>% mutate_all(as.character)   sample <- pivot_longer(sample,     cols = c(-SampleID, -SiteID, -SAMPLE_DATE),     names_to = \"question\",     values_to = \"response\"   )   sample <- select(sample, -\"SAMPLE_DATE\")   names(sample) <- c(\"sample_id\", \"location_id\", \"question\", \"response\")    location <- output$Uncertainty   location <- location %>% mutate_all(as.character)   location <- pivot_longer(location,     cols = c(-SiteID),     names_to = \"question\",     values_to = \"response\"   )   names(location) <- c(\"location_id\", \"question\", \"response\")   results <- bind_rows(sample, location)   results$parameter <- \"Phytobenthos (diatoms)\"   results <- mutate(results,     question = ifelse(question == \"WFDClass\",       \"Class\",       question     )   )    years <- data %>%     mutate(\"year\" = lubridate::year(date_taken)) %>%     filter(parameter == \"River Diatoms\") %>%     group_by(location_id) %>%     summarise(\"response\" = paste(unique(.$year), collapse = \",\"))    years$question <- \"Years included\"   years$parameter <- \"Phytobenthos (diatoms)\"   results <- bind_rows(results, years)   return(results) }"},{"path":"https://ecodata1.github.io/hera/articles/darleq3.html","id":"outcome","dir":"Articles","previous_headings":"","what":"Outcome","title":"DARLEQ3","text":"outcome assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/darleq3.html","id":"check","dir":"Articles","previous_headings":"","what":"Check","title":"DARLEQ3","text":"Run checks assessment.","code":"#> Test passed  #> Test passed"},{"path":"https://ecodata1.github.io/hera/articles/darleq3.html","id":"update","dir":"Articles","previous_headings":"","what":"Update","title":"DARLEQ3","text":"Update catalogue assessments make available.","code":"#> ✔ Setting active project to '/home/runner/work/hera/hera' #> ✔ Saving 'catalogue' to 'data/catalogue.rda' #> • Document your data (see 'https://r-pkgs.org/data.html')"},{"path":"https://ecodata1.github.io/hera/articles/darleq3.html","id":"test","dir":"Articles","previous_headings":"","what":"Test","title":"DARLEQ3","text":"section tests assessment usable using assessment function.","code":"#> Hello from hera, ...work in progress! #> Hello from hera, ...work in progress! #> Warning in CPL_crs_from_input(x): GDAL Message 1: +init=epsg:XXXX syntax is #> deprecated. It might return a CRS with a non-EPSG compliant axis order. #> # A tibble: 237 × 5 #>    sample_id location_id question        response         parameter              #>    <chr>     <chr>       <chr>           <chr>            <chr>                  #>  1 1250462   8175        Alkalinity      121.9125401      Phytobenthos (diatoms) #>  2 1250462   8175        lake_TYPE       HA               Phytobenthos (diatoms) #>  3 1250462   8175        Total_count     312              Phytobenthos (diatoms) #>  4 1250462   8175        Percent_in_TDI4 99.3589743589744 Phytobenthos (diatoms) #>  5 1250462   8175        N_TDI4          37               Phytobenthos (diatoms) #>  6 1250462   8175        N2_TDI4         11.09            Phytobenthos (diatoms) #>  7 1250462   8175        Max_TDI4        20.51            Phytobenthos (diatoms) #>  8 1250462   8175        TDI4            64.6129032258064 Phytobenthos (diatoms) #>  9 1250462   8175        eTDI4           53.8155110499444 Phytobenthos (diatoms) #> 10 1250462   8175        EQR_TDI4        0.61296937701247 Phytobenthos (diatoms) #> # ℹ 227 more rows"},{"path":"https://ecodata1.github.io/hera/articles/darleq3.html","id":"launch-app","dir":"Articles","previous_headings":"","what":"Launch app","title":"DARLEQ3","text":"interactive application displaying results assessment.","code":""},{"path":[]},{"path":[]},{"path":"https://ecodata1.github.io/hera/articles/deployment_guide.html","id":"quick-start","dir":"Articles","previous_headings":"Work In Progress!…","what":"Quick Start","title":"Deploy Guide","text":"add new assessment hera package install hera package Open new File > New File > R Markdown Select ‘Template’ Search ‘Deployment Template’ open Change ‘Deployment Template’ title match assessment name Save document Congratulations! now new deployment template ready populate. Next, complete following sections get assessment fully operational!","code":"install.packages(\"devtools\") devtools::install_github(\"aquaMetrics/hera\", dependencies = TRUE) library(hera)"},{"path":[]},{"path":[]},{"path":[]},{"path":"https://ecodata1.github.io/hera/articles/development_guide.html","id":"quick-start","dir":"Articles","previous_headings":"","what":"Quick Start","title":"Development Guide","text":"add new assessment, install hera package. Open new File > New File > R Markdown Select ‘Template’ Search ‘Assessment Template’ open Change title: \"Trophic Diatom Index\" title match assessment name Change vignette entry %\\VignetteIndexEntry{Trophic Diatom Index} match name assessment. Save document using name---assessment format package vignette folder. Congratulations! now new assessment template ready populate. Complete following sections.","code":"install.packages(\"devtools\") devtools::install_github(\"aquaMetrics/hera\", dependencies = TRUE) library(hera)"},{"path":"https://ecodata1.github.io/hera/articles/development_guide.html","id":"description","dir":"Articles","previous_headings":"","what":"Description","title":"Development Guide","text":"first piece information add details assessment called status. table shows options choose fields required.","code":""},{"path":"https://ecodata1.github.io/hera/articles/development_guide.html","id":"example","dir":"Articles","previous_headings":"Description","what":"Example","title":"Development Guide","text":"code creates tibble/dataframe called ‘standard’ containing metadata LEAFPACS parameter. tibble later saved ‘hera’ package future reference. Code:","code":"description <- tribble(   ~question, ~response,   \"name_short\", \"LEAFPACS\",   \"name_long\", \"UKTAG River Assessment Method Macrophytes and Phytobenthos\",   \"parameter\", \"River Macrophytes\",   \"status\", \"testing\" )  description ## # A tibble: 4 × 2 ##   question   response                                                   ##   <chr>      <chr>                                                      ## 1 name_short LEAFPACS                                                   ## 2 name_long  UKTAG River Assessment Method Macrophytes and Phytobenthos ## 3 parameter  River Macrophytes                                          ## 4 status     testing"},{"path":"https://ecodata1.github.io/hera/articles/development_guide.html","id":"input","dir":"Articles","previous_headings":"","what":"Input","title":"Development Guide","text":"Create demo input data. example:","code":"input <- tibble(   sample_id = c(\"12345\", \"12345\"),   question = c(\"Taxon abundance\", \"Alkalinity\"),   response = c(\"12\", \"45\"),   label = c(\"Gomphonema olivaceum\", NA),   parameter = c(\"River Diatoms\", \"Chemistry\"),   type = c(\"number\", \"number\"),   max = c(NA, NA),   min = c(NA, NA),   source = c(\"sepa_ecology_results\", \"location_attributes\") ) input ## # A tibble: 2 × 9 ##   sample_id question        response label    parameter type  max   min   source ##   <chr>     <chr>           <chr>    <chr>    <chr>     <chr> <lgl> <lgl> <chr>  ## 1 12345     Taxon abundance 12       Gomphon… River Di… numb… NA    NA    sepa_… ## 2 12345     Alkalinity      45       NA       Chemistry numb… NA    NA    locat…"},{"path":"https://ecodata1.github.io/hera/articles/development_guide.html","id":"assessment","dir":"Articles","previous_headings":"","what":"Assessment","title":"Development Guide","text":"magic happens… Initially, may easier write placeholder expect function return. example given assessment template. script must return dataframe three columns: sample_id, question response. instance, questions EQR, Complaint, Inspection Outcome. responses 0.6, TRUE, FAIL. sample_id much input data. Using input, write function assess data. may call web service, import data elsewhere, run script another programming language (python, matlab etc).","code":""},{"path":"https://ecodata1.github.io/hera/articles/development_guide.html","id":"outcome","dir":"Articles","previous_headings":"","what":"Outcome","title":"Development Guide","text":"section display outcome assessemnt function show example outcome assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/development_guide.html","id":"checklist","dir":"Articles","previous_headings":"","what":"Checklist","title":"Development Guide","text":"final sections cover various check test don’t need edited. However, may indicate problems description, input, assessment outcomes. data formatted using hera_format function neatly present within documentation assessment.hera_format function also check data errors omissions.","code":"standard_format <- hera:::hera_format(description = description) # format table standard_format %>%   knitr::kable()"},{"path":"https://ecodata1.github.io/hera/articles/development_guide.html","id":"update","dir":"Articles","previous_headings":"","what":"Update","title":"Development Guide","text":"Access pre-existing metadata within hera package. metadata saved catalogue nested dataframe. may need unnest list columns see information.","code":"catalogue %>%   filter(assessment == \"Example\") %>%   unnest(data) ## # A tibble: 0 × 3 ## # ℹ 3 variables: assessment <chr>, data <???>, assessment_function <list>"},{"path":"https://ecodata1.github.io/hera/articles/development_guide.html","id":"launch","dir":"Articles","previous_headings":"","what":"Launch","title":"Development Guide","text":"TODO","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"propose regulatory tools share common set design principles, interfaces data structures. Specifically, propose official collection R packages designed provide collaborative workflow building using assessment tools. turn, packages unified single package called ‘hera’. provides common interface run regulatory assessments. expect process facilitate code re-use, faster integration knowledge exchange method developers practitioners.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"UKTAG guided development impressive range classification tools. involved many developers, researchers experts dedicating time effort creating tools better understand pressures environment. confident many future opportunities collaboration tool development response changing environmental pressures improving scientific understanding. access modelling tools become routine, expect proliferation models indices years ahead. instance, new tools diagnosing pressures, updates existing tools catchment scale planning. aid better understanding environment effectively combining multiple models tools, propose share common design philosophy aid integration collaboration.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"key-ideas","dir":"Articles","previous_headings":"","what":"Key Ideas","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"aims shared design philosophy regulatory classification R packages include: Create single user interfaces, similar data formats operating procedures. Allow outputs multiple tools quickly generated combined together. Shorten time development integration Agencies systems. Clearer path researcher engagement model development. Make easier share re-use code tools common functions. Share data quality standards data validation code. Apply similar approaches code review, testing documentation.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"preparing-for-future","dir":"Articles","previous_headings":"3 Key Ideas","what":"Preparing for future","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"next 10 years… assume likely aquatic ecological models subsumed large scale environmental climate models. ‘total environment’ models may instance use climate change models forecast impact invertebrates, water-use models predict impact fish spatial planning tools impact nutrient levels. outputs used across regulatory reporting RBMP, flood management, biodiversity improvements, carbon sequestering etc. Allowing multi-discipline assessment impacts trade-offs planning scenario proposed measures - ensuring well-informed decisions-making. ecological data along supporting data chemistry, climate, meteorological, geological, satellite imagery, freely easily accessible. assume agencies upload data fish counter data, plant DNA aerial imagery etc, ‘lake’ environmental data. take step towards vision, underlying design models tools must modular easy connect integrate variety ways.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"detailed-design","dir":"Articles","previous_headings":"","what":"Detailed Design","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"aid collaboration respond changing environmentally pressures, propose creating joint collections packages share understanding environment providing software infrastructure lighten burden mundane tasks involved maintaining deploying new models interfaces. proposal influenced work within climate change research community Climate Modelling Diagnostics Toolkit, MET office’s unified model approach. well best software practices -going work R community ropenSci research projects Virtual Observatory.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"shared-packages","dir":"Articles","previous_headings":"4 Detailed Design","what":"Shared Packages","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"Currently number classification tool R packages shared github: darleq3 - Phytobenthos fsc2 - Scottish river fish rict - General invertebrate classification propose tools become part official collection packages work towards making inter-operable via hera package.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"key-steps","dir":"Articles","previous_headings":"4 Detailed Design","what":"Key Steps","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"introduce prototype R package called hera. key idea, hera provides common interface existing WFD packages future developments. achieved set shared functions required run report classification. builds best practice idea run many models simultaneously R keeping input output data formats simple homogeneous. explain function detail . summary, step represents function within hera package. allows re-use code rules existing future tool development. Steps 1. Validation 2. Indices/metrics 3. Assessment 4. Reporting examples illustrative RFC implemented. Keep mind examples full, complete accurate. data structure, naming details change, presented rough draft.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"validation","dir":"Articles","previous_headings":"4 Detailed Design > 4.2 Key Steps","what":"Validation","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"Firstly, sense-check predictor observation data expect limits formatting rules. Additionally, validation check data within expect parameter space based training data used create classification model. validation() function returns passing data list warnings/fails.","code":"# install.packages(\"devtools\") # devtools::install_github(\"ecodata1/hera\") demo_data <- hera::demo_data data <- validation(demo_data) data[5, ] # A tibble: 1 × 21   location_id location_description           easting northing latitude longitude   <chr>       <fct>                            <dbl>    <dbl>    <dbl>     <dbl> 1 8175        River Eden @ Kemback Gauging …  341452   715796     56.3     -2.95 # ℹ 15 more variables: date_taken <dttm>, sample_id <chr>, question <chr>, #   response <chr>, mean_alkalinity <dbl>, grid_reference <chr>, #   standard <chr>, quality_element <chr>, water_body_id <dbl>, label <fct>, #   dist_from_source <dbl>, slope <dbl>, source_altitude <dbl>, #   parameter <chr>, year <dbl>"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"assess","dir":"Articles","previous_headings":"4 Detailed Design > 4.2 Key Steps","what":"Assess","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"Using assess() function, can calculate required: 1. Indices/Metrics (summary stats) 2. Predictions (output models) 3. Classification/Reports (assessments combining summary prediction stats) ‘assessment’ stage includes type index, test categorisation data. WFD classification, compliance check, bathing water discharge assessment. Broadly, type grading assessment. default assess() function run assessments possible based data provided. r data %>%    assess() %>%   select(sample_id, question, response) %>%   slice_sample(n = 4) Alternatively, can select list specific assessments catalogue run required.","code":"[1] \"MPFF Compliance\"           \"Macroinvertebrate Metrics\" data %>%   assess(name = catalogue$assessment[1:2]) %>%   select(sample_id, question, response) %>%   slice_sample(n = 4) # A tibble: 4 × 3   sample_id question        response           <chr>     <chr>           <chr>            1 3294945   SPEAR class TL2 Good             2 1101214   Riverfly ASPT   2.33333333333333 3 621928    EPSI Score TL2  77.6726304894278 4 443815    Riverfly ASPT   2"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"assessment-reports","dir":"Articles","previous_headings":"4 Detailed Design > 4.2 Key Steps > 4.2.2 Assess","what":"Assessment Reports","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"catalogue can contain complex reporting assessments compile, group presents one assessment output. instance running presenting number WFD assessments, grouping water body hierarchy River Basin Management Plan.","code":"# TODO! assess(demo_data, 'rbmp_report')"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"diagnosis","dir":"Articles","previous_headings":"4 Detailed Design > 4.2 Key Steps > 4.2.2 Assess","what":"Diagnosis","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"well classification water quality, additional need diagnose potential pressures. , can add assessment catalogue diagnostic reporting. use assess() function build custom report help diagnose potential pressures.","code":"# TODO! assess(demo_data, 'diagnose_wfd_pressures') %>%  select(sample_id, question, response) head()"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"aggegation","dir":"Articles","previous_headings":"4 Detailed Design > 4.2 Key Steps > 4.2.2 Assess","what":"Aggegation","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"facilitate general data exploration, aggregate helper function can group outputs season, year, multi-year water body required. allows standard way aggregate data within hera toolset.","code":"aggregate <- aggregate(demo_data, c(\"year\",\"season\",\"waterbody\")) head(class)"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"compare","dir":"Articles","previous_headings":"4 Detailed Design > 4.2 Key Steps > 4.2.2 Assess","what":"Compare","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"compare helper function allows generic comparison years, locations samples allow general data analysis comparison. Another, example comparing two samples (perhaps downstream):","code":"# TODO! compare_report <- compare(new_data, old_data) compare_report # TODO! compare_report <- compare(site_one, site_two) compare_report"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"scenarios","dir":"Articles","previous_headings":"4 Detailed Design > 4.2 Key Steps > 4.2.2 Assess","what":"Scenarios","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"number forecasting scenario tools incorporated either projecting current trends assessing impact proposed measures.","code":"# TODO! assess(demo_data, trends, scenario=\"wfd_forecast\") %>%   head()  assess(demo_data, measures, scenario=\"measure_impact\") %>%  head()"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"the-whole-game","dir":"Articles","previous_headings":"4 Detailed Design > 4.2 Key Steps","what":"The Whole Game","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"part don’t expect users go steps. developers researchers useful think classification within framework discrete steps. majority end users, agency staff consultants, can open GUI hera_app() visit website directly. Furthermore, agencies can integrate functions systems using web services. Please see demo web service api documentation using opencpu hosted packages.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"lots-of-datasets---one-underlying-data-structure","dir":"Articles","previous_headings":"4 Detailed Design","what":"Lots of Datasets - one underlying data structure?","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"Models rely observed sampling training. Samples come range forms points, transects, images, grabs, DNA etc. general feature modelling based able predict expect find whatever sampling technique deploy. sample fundamental observation compare prediction. samples discreet, either observed instantaneously perhaps minutes hours (dynamic changes significant). Multiple samples can aggregated smooth variance sample still remains fundamental building block. sample single pixel aerial image salmon moving fish counter. still make predictions expect sample like even true picture emerges several samples aggregated compared. Therefore, data share similarities, consist samples observations. additionally sample predictor variables allow us predict expected reference values outcomes.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"data-dictionary","dir":"Articles","previous_headings":"4 Detailed Design > 4.3 Lots of Datasets - one underlying data structure?","what":"Data dictionary","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"number data dictionaries, metadata standards semantic data definition across disciplines organisations. ’s unclear exactly define input output datasets. Therefore, propose using common definition standards possible. similar way climate model communities use Climate Forecast Standard Names. Europe Environment Agency produced data dictionary reporting. However, mainly high-level reporting. particular, taxonomic results exchanged using data structure. However, use aspects standard within hera aid onward reporting EEA.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"what-does-this-look-like","dir":"Articles","previous_headings":"4 Detailed Design > 4.3 Lots of Datasets - one underlying data structure?","what":"What does this look like?","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"small sample demo dataset demo_data contains diatoms, macrophytes inverts quality elements.","code":"# A tibble: 5 × 4 # Groups:   quality_element [5]   location_description             date_taken          sample_id quality_element   <fct>                            <dttm>              <chr>     <chr>           1 River Eden @ Kemback Gauging St… 2017-07-20 12:15:00 3256506   Algal_RQB       2 River Eden @ Kemback Gauging St… 2011-05-04 13:45:00 1800006   Alien Species   3 River Eden @ Kemback Gauging St… 2017-05-17 15:00:00 3201863   Comment         4 River Eden @ Kemback Gauging St… 2011-10-07 13:22:00 1912578   Diatom Summary  5 River Eden @ Kemback Gauging St… 2014-10-02 12:30:00 2632159   Diatom Survey …"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"book-keeping-variables","dir":"Articles","previous_headings":"4 Detailed Design > 4.3 Lots of Datasets - one underlying data structure?","what":"Book-keeping variables","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"First , ‘book-keeping’ variables. allow us reference data associated particular samples, locations WFD methods. allow results aggregate different levels. data passed hera must four variables. ad hoc reporting, consultancies students etc don’t routinely record unique sample ids, sample_id generate date_taken location_id provided. three variables minimal required, practice water_body_id maybe required aggregation simply location_description NGR etc help reference sites easily. restriction number extra columns extra columns appended outputs.","code":"# A tibble: 5 × 4   location_id sample_id date_taken          quality_element           <chr>       <chr>     <dttm>              <chr>                   1 8175        3256506   2017-07-20 12:15:00 Macrophyte Reach Survey 2 8175        3256506   2017-07-20 12:15:00 Macrophyte Reach Survey 3 8175        3256506   2017-07-20 12:15:00 Macrophyte Reach Survey 4 8175        3256506   2017-07-20 12:15:00 Macrophyte Reach Survey 5 8175        3256506   2017-07-20 12:15:00 Macrophyte Reach Survey"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"observations","dir":"Articles","previous_headings":"4 Detailed Design > 4.3 Lots of Datasets - one underlying data structure?","what":"Observations","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"observation consists three variables question, response. question variable identifies determined alkalinity depth etc. response value observed recorded question. example diatom records, invert data river flow shared input format. theory, required. However ease interacting existing datasets ad hoc data, third column label useful due historic way taxon data usually stored.","code":"# A tibble: 7,106 × 2    question        response          <chr>           <chr>           1 Site altitude   7               2 Source altitude 210             3 nems alkalinity 118.8889        4 Mean alkalinity 118.8889        5 nems slope      2.6000          6 Slope           2.6000          7 Dist to source  36.4            8 Site NGR        NO 41452 15796  9 Easting         341452         10 Northing        715796         # ℹ 7,096 more rows # A tibble: 5 × 3   question               response label            <chr>                  <chr>    <fct>          1 Taxon abundance        1        Hydropsychidae 2 Taxon abundance        50       Oligochaeta    3 BMWP Score             7.0      Rhyacophilidae 4 TDLR                   3        Nitzschia sp.  5 Plant functional group 0        Didymodon"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"predictors","dir":"Articles","previous_headings":"4 Detailed Design > 4.3 Lots of Datasets - one underlying data structure?","what":"Predictors","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"Predictive variables temperature, altitude, slope added additional columns. trade-predictor variables added row dataset, increasing size dataset. However make data analysis straightforward repeated data can easily compressed size becomes issue. instance, nested JSON data dataframes R.","code":"# A tibble: 7,106 × 3    mean_alkalinity grid_reference slope              <dbl> <chr>          <dbl>  1              75 NO 41452 15796     2  2              75 NO 41452 15796     2  3              75 NO 41452 15796     2  4              75 NO 41452 15796     2  5              75 NO 41452 15796     2  6              75 NO 41452 15796     2  7              75 NO 41452 15796     2  8              75 NO 41452 15796     2  9              75 NO 41452 15796     2 10              75 NO 41452 15796     2 # ℹ 7,096 more rows"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"assessments","dir":"Articles","previous_headings":"4 Detailed Design > 4.3 Lots of Datasets - one underlying data structure?","what":"Assessments","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"outputs presented consistent format making outputs different models instantly comparable portable.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"data-input","dir":"Articles","previous_headings":"4 Detailed Design","what":"Data Input","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"students consultancies requiring ad hoc usage, templates documentation preparing data provided. Agencies, data queries can written prepare outputs correct format. instance, prototype function pull data Environment Agency’s data.gov.uk web service convert required hera input format. can run EA data hera:","code":"environment_agency_data <- hera:::get_data(location_id = c(43378, 92751)) tibble(environment_agency_data) report <- hera::assess(environment_agency_data) report %>%   select(date_taken, question, response) %>%   unique()"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"shared-data-tables","dir":"Articles","previous_headings":"4 Detailed Design","what":"Shared Data Tables","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"Following data tables shared hera… Validation Rules Indices, Model Environmental Standards Taxon Table EQR / assessment / compliance boundaries Parameter Hierarchy","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"models-and-environmental-standards-names","dir":"Articles","previous_headings":"4 Detailed Design > 4.5 Shared Data Tables","what":"Models and Environmental Standards names","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"","code":"hera::catalogue # A tibble: 5 × 3   assessment                data               assessment_function   <chr>                     <list>             <list>              1 MPFF Compliance           <tibble [34 × 10]> <fn>                2 Macroinvertebrate Metrics <tibble [23 × 10]> <fn>                3 RICT                      <tibble [30 × 12]> <fn>                4 DARLEQ3                   <tibble [36 × 12]> <fn>                5 Bankside Consistency      <tibble [18 × 12]> <fn>"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"model-platform","dir":"Articles","previous_headings":"4 Detailed Design","what":"Model platform","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"RFC mainly looking share design inputs outputs classification tools. framework however encourage shared principles thinking approach modelling required drives classification method. However, see need prescribe modelling program software. Researchers can download reference predictor data required use software desire. Ultimately, model need called R. either model needs written R language can called R (Python, fortran, C++ etc). Alternatively, researchers can’t provide api R call, recommendation use R - integrates directly pipeline. modelling completed, model object saved deployed. existing future data collected using platform run model sample level. Researchers can build tools display aggregate sample level results required (Waterbody, Year, Catchment etc). possible share techniques producing Confidence Class, assessment data suitability adjustment factors etc.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"how-we-teach-this","dir":"Articles","previous_headings":"","what":"How We Teach This","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"new regulatory developments updates requirements identified, lead contacts agencies method developers ‘-boarded’ demonstrate design principles collaborative framework packages. skill development required training can provided, additional external internal support agency commissioning work. workshop lead data experts / R coders agency delivers institutional knowledge internally developed tools fit shared design philosophy well setting expectations collaboration external researchers.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"sharing","dir":"Articles","previous_headings":"5 How We Teach This","what":"Sharing","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"Hera allows multiple ecological elements assessed interface. just interface shared. areas infrastructure shared including: Reporting comparison tools can also shared multiple elements. Validation checks universally required mechanisms shared easily configurable new models/methods. Testing infrastructure. Confidence class data suitability algorithms.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"organisation","dir":"Articles","previous_headings":"5 How We Teach This","what":"Organisation","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"UKTAG sub-groups nominated leads devolved agencies contribute new method develops tools shared collection packages. tools agency specific, also make use platform required. agencies commission new tools developed, researchers can upload predictive variables, reference data models central repo easier collaboration.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"alternatives","dir":"Articles","previous_headings":"","what":"Alternatives","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"Status Quo - Future development takes form bespoke, custom code self-contained R packages Excel spreadsheets. code re-use, collaboration consistency tools/metrics/assessments. computational document standards Python Julia, JS based Jupiter Quarto documents. Currently, code either Excel R based. wish avoid re-writing R code languages. doesn’t preclude future developments using languages computational document standards. Web assembly - Compile R, Python, Julia, C++ etc widely supported Web Assembly language fast use within web browser (offline). prototype stage R Python many existing libraries compile Web Assembly. Possibly future may option. current tools integrating combining languages provide broad enough consistency/compatibility even back-end server required. Requiring back-end server can impact offline native usage situations mobile devices. instance, R supports MacOS, Linux Windows. R isn’t officially supported run locally/natively Android iOS. devices, R must run web server requires mobile/wifi signal communicate device. Using Web Assembly future may avoid need web-server mobile / offline devices.","code":""},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"unresolved-questions","dir":"Articles","previous_headings":"","what":"Unresolved Questions","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"reference/predictor data combined single repository / web service?","code":""},{"path":[]},{"path":[]},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"fcs2-tool","dir":"Articles","previous_headings":"8 Appendix > 8.1 List of Current Data Structures in R packages","what":"FCS2 tool","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"Demo input data format (truncated) full list column names Ouput","code":"DataHeldBy SiteCode Alternative.site.code Repeat.check SiteName 1         EA   525052                    NA            N    13809 2         EA   507441                    NA            Y    13810 3         EA   525051                    NA            N    34611 4         EA   122881                    NA            Y     5435   Site.description ... 1            13809 ... 2            13810 ... 3            34611 ... 4             5435 ...  [1] #DataHeldBy#                 #SiteCode#                    [3] #Alternative.site.code#      #Repeat.check#                [5] #SiteName#                   #Site.description#            [7] #Easting#                    #Northing#                    [9] #NGR#                        #SurveyDate#                 [11] #WBId#                       #WBName#                     [13] #NumberOfRuns#               #SurveyArea#                 [15] #WetWidth#                   #Slope#                      [17] #BarrierType#                #ImpassableBarriers#         [19] #Sense.check.passed.#        #CatchmentAreaUpstream#      [21] #CatchmentDrainageDirection# #GeologyClass#               [23] #Altitude#                   #DistanceFromSource#         [25] #DistanceToSea#              #AnnualMeanFlow#             [27] #AlkalinityValue#            #TotalPValue#                [29] #DOCValue#                   #SuspendedSolidsValue#       [31] #IOH.hydrometric.area#       #HydrometricAreaNo#          [33] #LandUse.AgriculturalAreas#  #LandUse.ConiferousForests#  [35] #LandUse.Wetlands#           #Substrate.Small#            [37] #Substrate.Large#            #Substrate.Bedrock#          [39] #Salmon_fry.Run1Total#       #Salmon_fry.Run2Total#       [41] #Salmon_fry.Run3Total#       #Salmon_fry.Run4Total#       [43] #Salmon_parr.Run1Total#      #Salmon_parr.Run2Total#      [45] #Salmon_parr.Run3Total#      #Salmon_parr.Run4Total#      [47] #Trout_fry.Run1Total#        #Trout_fry.Run2Total#        [49] #Trout_fry.Run3Total#        #Trout_fry.Run4Total#        [51] #Trout_parr.Run1Total#       #Trout_parr.Run2Total#       [53] #Trout_parr.Run3Total#       #Trout_parr.Run4Total# WBName ... 1         EA 03/09/2015   525052    13809 10675                          ... 2         EA 04/09/2015   507441    13810 10675 White Esk (u/s Rae Burn) ... 3         EA 03/09/2015   525051    34611 10676                          ... 4         EA 01/09/2015   122881     5435 10676            Garwald Water ...  [1] #DataHeldBy#                                   [2] #SurveyDate#                                   [3] #SiteCode#                                     [4] #SiteName#                                     [5] #WBId#                                         [6] #WBName#                                       [7] #All species WB EQR Bad %#                     [8] #All species WB EQR Poor %#                    [9] #All species WB EQR Moderate %#               [10] #All species WB EQR Good %#                   [11] #All species WB EQR High %#                   [12] #All species WB EQR mean#                     [13] #All species survey EQR Bad %#                [14] #All species survey EQR Poor %#               [15] #All species survey EQR Moderate %#           [16] #All species survey EQR Good %#               [17] #All species survey EQR High %#               [18] #All species survey EQR mean#                 [19] #Salmon_fry WB EQR mean#                      [20] #Salmon_fry survey EQR mean#                  [21] #Salmon_fry observed total catch#             [22] #Salmon_fry probability present#              [23] #Salmon_fry expected total catch if present#  [24] #Salmon_fry expected total catch#             [25] #Salmon_parr WB EQR mean#                     [26] #Salmon_parr survey EQR mean#                 [27] #Salmon_parr observed total catch#            [28] #Salmon_parr probability present#             [29] #Salmon_parr expected total catch if present# [30] #Salmon_parr expected total catch#            [31] #Trout_fry WB EQR mean#                       [32] #Trout_fry survey EQR mean#                   [33] #Trout_fry observed total catch#              [34] #Trout_fry probability present#               [35] #Trout_fry expected total catch if present#   [36] #Trout_fry expected total catch#              [37] #Trout_parr WB EQR mean#                      [38] #Trout_parr survey EQR mean#                  [39] #Trout_parr observed total catch#             [40] #Trout_parr probability present#              [41] #Trout_parr expected total catch if present#  [42] #Trout_parr expected total catch#"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"darleq-tool","dir":"Articles","previous_headings":"8 Appendix > 8.1 List of Current Data Structures in R packages","what":"Darleq Tool","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"Input data DARLEQ3 tool list dataframes. ’s example input data format (truncated) full list column names Output (list dataframes)","code":"AC023A AC083A AC143A AC161A AC9999  AD009A   AM001A AM004A ... SPR001 0.000000      0      0      0      0 0.31348 0.000000      0 ... AUT001 0.000000      0      0      0      0 0.00000 0.000000      0 ... SPR002 0.332226      0      0      0      0 0.00000 0.332226      0 ... AUT002 0.000000      0      0      0      0 0.00000 0.000000      0 ...   [1] \"AC023A\" \"AC083A\" \"AC143A\" \"AC161A\" \"AC9999\" \"AD009A\" \"AM001A\" \"AM004A\"   [9] \"AM011A\" \"AM012A\" \"AM013A\" \"AM084A\" \"AM9999\" \"AP001A\" \"AS001A\" \"AS003A\"  [17] \"AU003A\" \"AU9999\" \"BR001A\" \"BR9999\" \"CA002A\" \"CA9999\" \"CC9999\" \"CI002A\"  [25] \"CI005A\" \"CL001A\" \"CM004A\" \"CM006A\" \"CM007A\" \"CM009A\" \"CM013A\" \"CM022A\"  [33] \"CM038A\" \"CM041A\" \"CM9999\" \"CN001A\" \"CO001A\" \"CO001B\" \"CO001C\" \"CO005A\"  [41] \"CO010A\" \"CO9999\" \"CV001A\" \"CV005A\" \"CY003A\" \"CY011A\" \"CY019A\" \"CY9999\"  [49] \"DD001A\" \"DE001A\" \"DP007A\" \"DP012A\" \"DP9999\" \"DT003A\" \"DT004A\" \"DT010A\"  [57] \"DT021A\" \"DT022A\" \"DT9999\" \"EC001A\" \"EL001A\" \"EP9999\" \"EU002A\" \"EU009A\"  [65] \"EU009C\" \"EU047A\" \"EU070A\" \"EU9999\" \"EY003A\" \"EY004A\" \"EY005A\" \"EY011A\"  [73] \"EY015A\" \"EY016A\" \"EY017A\" \"EY9999\" \"FA021A\" \"FF001A\" \"FF002A\" \"FF9999\"  [81] \"FR007A\" \"FR007C\" \"FR008A\" \"FR009A\" \"FR009B\" \"FR019A\" \"FR026A\" \"FR9999\"  [89] \"FU001A\" \"FU002A\" \"FU037A\" \"GO001A\" \"GO003A\" \"GO004A\" \"GO006A\" \"GO013A\"  [97] \"GO013C\" \"GO019A\" \"GO023A\" \"GO023B\" \"GO024C\" \"GO027A\" \"GO029A\" \"GO050A\" [105] \"GO052A\" \"GO055A\" \"GO066A\" \"GO9999\" \"GY001A\" \"GY005A\" \"HA001A\" \"HN001A\" [113] \"LU001A\" \"LU003A\" \"MA9999\" \"ME015A\" \"MR001A\" \"MR001B\" \"NA003A\" \"NA007A\" [121] \"NA008A\" \"NA009A\" \"NA021A\" \"NA023A\" \"NA026A\" \"NA027A\" \"NA030A\" \"NA035A\" [129] \"NA037A\" \"NA042A\" \"NA051A\" \"NA054A\" \"NA063A\" \"NA066A\" \"NA080A\" \"NA084A\" [137] \"NA095A\" \"NA112A\" \"NA114A\" \"NA124A\" \"NA134A\" \"NA433A\" \"NA433D\" \"NA462A\" [145] \"NA675A\" \"NA745A\" \"NA751A\" \"NA764A\" \"NA768A\" \"NA9999\" \"NE008A\" \"NI002A\" [153] \"NI005A\" \"NI006A\" \"NI008A\" \"NI009A\" \"NI010A\" \"NI014A\" \"NI015A\" \"NI017A\" [161] \"NI021A\" \"NI024A\" \"NI025A\" \"NI027A\" \"NI028A\" \"NI031A\" \"NI033A\" \"NI034A\" [169] \"NI042A\" \"NI043A\" \"NI044A\" \"NI046A\" \"NI049A\" \"NI052A\" \"NI065A\" \"NI080A\" [177] \"NI099A\" \"NI110A\" \"NI152A\" \"NI164B\" \"NI166A\" \"NI171A\" \"NI198A\" \"NI199A\" [185] \"NI212A\" \"NI9999\" \"PE002A\" \"PI014A\" \"PI9999\" \"PS001A\" \"RC002A\" \"RE001A\" [193] \"SA003A\" \"SA012A\" \"SL001A\" \"SL002A\" \"SR001A\" \"SR002A\" \"SS002A\" \"SS003A\" [201] \"ST001A\" \"ST9999\" \"SU001A\" \"SU032A\" \"SU073A\" \"SU9999\" \"SY001A\" \"SY003A\" [209] \"SY004A\" \"SY004B\" \"SY013A\" \"SY043A\" \"TA001A\" \"TA002A\" \"TE003A\" \"TF003A\" [217] \"TF015A\" \"TF9999\" \"TH038A\" \"TU003A\" \"UN9994\" \"UN9995\" \"YH001A\" \"ZZZ834\" [225] \"ZZZ835\" \"ZZZ842\" \"ZZZ844\" \"ZZZ846\" \"ZZZ847\" \"ZZZ852\" \"ZZZ859\" \"ZZZ866\" [233] \"ZZZ869\" \"ZZZ871\" \"ZZZ872\" \"ZZZ885\" \"ZZZ887\" \"ZZZ888\" \"ZZZ893\" \"ZZZ895\" [241] \"ZZZ896\" \"ZZZ897\" \"ZZZ900\" \"ZZZ901\" \"ZZZ905\" \"ZZZ907\" \"ZZZ908\" \"ZZZ910\" [249] \"ZZZ911\" \"ZZZ912\" \"ZZZ920\" \"ZZZ921\" \"ZZZ922\" \"ZZZ923\" \"ZZZ926\" \"ZZZ927\" [257] \"ZZZ939\" \"ZZZ941\" \"ZZZ949\" \"ZZZ953\" \"ZZZ980\" \"ZZZ982\" \"ZZZ985\" \"ZZZ986\" [265] \"ZZZ987\" [1] \"SampleID\"    \"SiteID\"      \"SAMPLE_DATE\" \"Alkalinity\"  \"Stream\"      [6] \"Reach\" N_TDI5LM N2_TDI5LM Max_TDI5LM   TDI5LM  eTDI5LM SPR001       41     12.39      16.93 55.60483 68.49447 AUT001       23      3.09      51.57 70.01608 68.49447 SPR002       55     13.14      20.93 70.66666 69.28261 AUT002       39      7.69      26.91 66.08840 69.28261 SPR003       39      9.37      27.30 50.40770 65.48689 AUT003       32      5.87      37.14 39.65652 65.48689    CoCB   ROM  CoCHG CoCMPB ROM_GM 43 0.00 20.41  98.43   1.57   1.57 33 0.00 39.91  96.99   3.01   3.01 42 0.00  0.00 100.00   0.00   0.00 41 0.00  0.00 100.00   0.00   0.00 36 0.21 87.48  12.56  87.44  12.56 35 0.00 28.74  86.12  13.88  13.88 [1] \"TDI5LM\" $N_samples [1] 100  $N_samples_gt_zero [1] 100  $N_taxa [1] 265  $N_taxa_gt_zero [1] 265"},{"path":"https://ecodata1.github.io/hera/articles/hera_specifications.html","id":"rict","dir":"Articles","previous_headings":"8 Appendix > 8.1 List of Current Data Structures in R packages","what":"RICT","title":"Request for Comment: Shared Design Principles for Creating and Deploying Regulatory Methods","text":"’s example input data format (truncated) full list column names Output","code":"SITE      Waterbody Year NGR Easting Northing Altitude Slope ... 1 MYR-GB-01-R Waterbody name 2016  SE   94200    91000       60   2.7 ... 2 MYR-GB-01-R Waterbody name 2017  SE   94200    91000       60   2.7 ... 3 MYR-GB-01-R Waterbody name 2018  SE   94200    91000       60   2.7 ... 4 MYR-GB-05-R Waterbody name 2016  TL   92100    27200       15   1.3 ...  [1] \"SITE\"                             \"Waterbody\"                         [3] \"Year\"                             \"NGR\"                               [5] \"Easting\"                          \"Northing\"                          [7] \"Altitude\"                         \"Slope\"                             [9] \"Discharge\"                        \"Velocity\"                         [11] \"Dist_from_Source\"                 \"Mean_Width\"                       [13] \"Mean_Depth\"                       \"Alkalinity\"                       [15] \"Boulder_Cobbles\"                  \"Pebbles_Gravel\"                   [17] \"Sand\"                             \"Silt_Clay\"                        [19] \"Hardness\"                         \"Calcium\"                          [21] \"Conductivity\"                     \"Spr_Season_ID\"                    [23] \"Spr_TL2_WHPT_ASPT (AbW,DistFam)\"  \"Spr_TL2_WHPT_NTaxa (AbW,DistFam)\" [25] \"Spr_Ntaxa_Bias\"                   \"Sum_Season_ID\"                    [27] \"Sum_TL2_WHPT_ASPT (AbW,DistFam)\"  \"Sum_TL2_WHPT_NTaxa (AbW,DistFam)\" [29] \"Sum_Ntaxa_Bias\"                   \"Aut_Season_ID\"                    [31] \"Aut_TL2_WHPT_ASPT (AbW,DistFam)\"  \"Aut_TL2_WHPT_NTaxa (AbW,DistFam)\" [33] \"Aut_Ntaxa_Bias\" ROW        SITE YEAR FAIL 1  11 TST-NI-11-R 2018  --- 2  15 TST-NI-03-D 2018  --- 3  16 TST-NI-04-D 2018  --- 4  17 TST-NI-05-D 2018  --- 5  23 TST-NI-11-D 2018  --- 6   3 TST-NI-03-R 2018  --- 7   4 TST-NI-04-R 2018  --- 8   5 TST-NI-05-R 2018  ---                                                                                WARNING 1 You provided LATITUDE: 55.2233002776773, max value used to train model: 55.1995835.  2 You provided LATITUDE: 55.2015356650978, max value used to train model: 55.1995835.  3 You provided LATITUDE: 55.2255867691652, max value used to train model: 55.1995835.  4 You provided LATITUDE: 55.2082654209923, max value used to train model: 55.1995835.  5 You provided LATITUDE: 55.2233002776773, max value used to train model: 55.1995835.  6 You provided LATITUDE: 55.2015356650978, max value used to train model: 55.1995835.  7 You provided LATITUDE: 55.2255867691652, max value used to train model: 55.1995835.  8 You provided LATITUDE: 55.2082654209923, max value used to train model: 55.1995835.    REPLACEMENT 1         --- 2         --- 3         --- 4         --- 5         --- 6         --- 7         --- 8         ---          SITE YEAR      WATERBODY H_NTAXA_spr_aut G_NTAXA_spr_aut 1 TST-NI-01-R 2018 Waterbody name           99.34            0.66 2 TST-NI-02-R 2018 Waterbody name            2.84           30.77 3 TST-NI-03-R 2018 Waterbody name           88.03            11.6 4 TST-NI-04-R 2018 Waterbody name           99.85            0.15   M_NTAXA_spr_aut ... 1               0 ... 2           55.33 ... 3            0.37 ... 4               0 ...  [1] \"SITE\"                              \"YEAR\"                               [3] \"WATERBODY\"                         \"H_NTAXA_spr_aut\"                    [5] \"G_NTAXA_spr_aut\"                   \"M_NTAXA_spr_aut\"                    [7] \"P_NTAXA_spr_aut\"                   \"B_NTAXA_spr_aut\"                    [9] \"mostProb_NTAXA_spr_aut\"            \"NTAXA_aver_spr_aut\"                [11] \"H_ASPT_spr_aut\"                    \"G_ASPT_spr_aut\"                    [13] \"M_ASPT_spr_aut\"                    \"P_ASPT_spr_aut\"                    [15] \"B_ASPT_spr_aut\"                    \"mostProb_ASPT_spr_aut\"             [17] \"ASPT_aver_spr_aut\"                 \"mintawhpt_spr_aut_H_MINTA_\"        [19] \"mintawhpt_spr_aut_G_MINTA_\"        \"mintawhpt_spr_aut_M_MINTA_\"        [21] \"mintawhpt_spr_aut_P_MINTA_\"        \"mintawhpt_spr_aut_B_MINTA_\"        [23] \"mintawhpt_spr_aut_mostProb_MINTA_\""},{"path":"https://ecodata1.github.io/hera/articles/macroinvertebrate-metrics.html","id":"welcome","dir":"Articles","previous_headings":"","what":"Welcome","title":"Macroinvertebrate Metrics","text":"document created following generic assessment guidance.","code":""},{"path":"https://ecodata1.github.io/hera/articles/macroinvertebrate-metrics.html","id":"description","dir":"Articles","previous_headings":"","what":"Description","title":"Macroinvertebrate Metrics","text":"Basic details assessment. Update ‘response’ values required.","code":""},{"path":"https://ecodata1.github.io/hera/articles/macroinvertebrate-metrics.html","id":"input","dir":"Articles","previous_headings":"","what":"Input","title":"Macroinvertebrate Metrics","text":"list questions required run assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/macroinvertebrate-metrics.html","id":"assessment","dir":"Articles","previous_headings":"","what":"Assessment","title":"Macroinvertebrate Metrics","text":"applicable, write function assess input data return outcome. example, metric, statistic, prediction etc.","code":"assessment_function <- function(data) {   # Calculated invert metrics...   # Note, any non-standard base R library must be call using require().   require(dplyr)   require(whpt)   require(macroinvertebrateMetrics)   input <- data   input$label <- trimws(input$label)   input <- dplyr::filter(     input,     parameter %in% c(       \"River Family Inverts\",       \"BANKSIDE_INVERTS\"     )   )   input <- dplyr::filter(input, question %in% c(     \"Taxon abundance\",     \"Live abundance\"   ))    input <- dplyr::select(     input, \"sample_id\", \"question\", \"response\", \"label\", \"parameter\"   )    output <- macroinvertebrateMetrics::calc_metric(input)   # riverfly <- macroinvertebrateMetrics::calc_riverfly(input)      # output <- dplyr::bind_rows(whpt, riverfly)    output <- dplyr::select(     output, \"sample_id\", \"question\", \"response\"    )   names(output) <- c(\"sample_id\", \"question\", \"response\")   return(output) }"},{"path":"https://ecodata1.github.io/hera/articles/macroinvertebrate-metrics.html","id":"outcome","dir":"Articles","previous_headings":"","what":"Outcome","title":"Macroinvertebrate Metrics","text":"outcome assessment.","code":"#> Loading required package: whpt #>  #> Attaching package: 'whpt' #> The following object is masked from 'package:hera': #>  #>     demo_data #> Loading required package: macroinvertebrateMetrics #>  #> Attaching package: 'macroinvertebrateMetrics' #> The following object is masked from 'package:whpt': #>  #>     demo_data #> The following object is masked from 'package:hera': #>  #>     demo_data"},{"path":"https://ecodata1.github.io/hera/articles/macroinvertebrate-metrics.html","id":"check","dir":"Articles","previous_headings":"","what":"Check","title":"Macroinvertebrate Metrics","text":"Run checks assessment.","code":"#> Test passed  #> Test passed"},{"path":"https://ecodata1.github.io/hera/articles/macroinvertebrate-metrics.html","id":"update","dir":"Articles","previous_headings":"","what":"Update","title":"Macroinvertebrate Metrics","text":"Update catalogue assessments make available. updating catalogue, rebuild package, click Build > Install Restart menu ‘Install Restart’ button Build pane.","code":"#> ✔ Setting active project to '/home/runner/work/hera/hera' #> ✔ Saving 'catalogue' to 'data/catalogue.rda' #> • Document your data (see 'https://r-pkgs.org/data.html')"},{"path":"https://ecodata1.github.io/hera/articles/macroinvertebrate-metrics.html","id":"test","dir":"Articles","previous_headings":"","what":"Test","title":"Macroinvertebrate Metrics","text":"section tests assessment usable using assessment function.","code":""},{"path":"https://ecodata1.github.io/hera/articles/macroinvertebrate-metrics.html","id":"launch-app","dir":"Articles","previous_headings":"","what":"Launch app","title":"Macroinvertebrate Metrics","text":"interactive application displaying results assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/mpff-compliance.html","id":"welcome","dir":"Articles","previous_headings":"","what":"Welcome","title":"Fish farm assessment","text":"document created following generic assessment guidance.","code":""},{"path":"https://ecodata1.github.io/hera/articles/mpff-compliance.html","id":"description","dir":"Articles","previous_headings":"","what":"Description","title":"Fish farm assessment","text":"Basic details assessment. Update ‘response’ values required.","code":""},{"path":"https://ecodata1.github.io/hera/articles/mpff-compliance.html","id":"input","dir":"Articles","previous_headings":"","what":"Input","title":"Fish farm assessment","text":"list questions required run assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/mpff-compliance.html","id":"assessment","dir":"Articles","previous_headings":"","what":"Assessment","title":"Fish farm assessment","text":"applicable, write function assess input data return outcome. example, metric, statistic, prediction etc.","code":"assessment_function <- function(data) {   data <- dplyr::filter(data, parameter == \"MPFF Compliance\")   if (nrow(data) > 0) {     results <- kraken::kraken(data, hera_format = TRUE, loess = TRUE)   } else {     return(NULL)   }    return(results) }"},{"path":"https://ecodata1.github.io/hera/articles/mpff-compliance.html","id":"outcome","dir":"Articles","previous_headings":"","what":"Outcome","title":"Fish farm assessment","text":"outcome assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/mpff-compliance.html","id":"check","dir":"Articles","previous_headings":"","what":"Check","title":"Fish farm assessment","text":"Run checks assessment.","code":"#> Test passed  #> Test passed"},{"path":"https://ecodata1.github.io/hera/articles/mpff-compliance.html","id":"update","dir":"Articles","previous_headings":"","what":"Update","title":"Fish farm assessment","text":"Update catalogue assessments make available. updating catalogue, rebuild package, click Build > Install Restart menu ‘Install Restart’ button Build pane.","code":"#> ✔ Setting active project to '/home/runner/work/hera/hera' #> ✔ Saving 'catalogue' to 'data/catalogue.rda' #> • Document your data (see 'https://r-pkgs.org/data.html')"},{"path":"https://ecodata1.github.io/hera/articles/mpff-compliance.html","id":"test","dir":"Articles","previous_headings":"","what":"Test","title":"Fish farm assessment","text":"section tests assessment usable using assessment function.","code":""},{"path":"https://ecodata1.github.io/hera/articles/mpff-compliance.html","id":"launch-app","dir":"Articles","previous_headings":"","what":"Launch app","title":"Fish farm assessment","text":"interactive application displaying results assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/rict.html","id":"welcome","dir":"Articles","previous_headings":"","what":"Welcome","title":"RICT","text":"document created following generic assessment guidance.","code":""},{"path":"https://ecodata1.github.io/hera/articles/rict.html","id":"description","dir":"Articles","previous_headings":"","what":"Description","title":"RICT","text":"Basic details assessment. Update ‘response’ values required.","code":""},{"path":"https://ecodata1.github.io/hera/articles/rict.html","id":"input","dir":"Articles","previous_headings":"","what":"Input","title":"RICT","text":"list questions required run assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/rict.html","id":"assessment","dir":"Articles","previous_headings":"","what":"Assessment","title":"RICT","text":"applicable, write function assess input data return outcome. example, metric, statistic, prediction etc.","code":"assessment_function <- function(data) {   # Calculated some statistic...   # Note, any non-standard base R library must be call using require().   require(rict)   require(macroinvertebrateMetrics)   message(unique(data$location_id))   metric_function <- catalogue[catalogue$assessment ==     \"Macroinvertebrate Metrics\", 3][[1]]   output <- metric_function[[1]](data)   output <- filter(output, question %in% c(\"WHPT_ASPT\", \"WHPT_NTAXA\"))     # Alkalinity ---------   # if(!any(names(data) %in% c(\"alkalinity\"))) {   #   alk <- hera:::mean_alkalinity(data)   #   data$alkalinity <- NULL   #   data <- inner_join(data, alk, by = join_by(\"sample_id\" == \"sample_number\"))   # }   if (!any(names(data) %in% \"alkalinity\")) {     predictors <- utils::read.csv(system.file(\"extdat\",       \"predictors.csv\",       package = \"hera\"     ), check.names = FALSE)     predictors$location_id <- as.character(predictors$location_id)     predict_data <- filter(predictors, location_id %in% unique(data$location_id))     output_location <- inner_join(output,       unique(data[, c(         \"location_id\",         \"sample_id\",         \"date_taken\"       )]),       by = \"sample_id\",       relationship = \"many-to-many\"     )      whpt_input <- inner_join(output_location, predict_data, by = \"location_id\")   } else {     # function to average predictors for each year? See sepaTools package?::     final_data <- data     final_data <- filter(final_data, analysis_repname == \"Invert Physical Data\")     if (nrow(final_data) < 1) {       return(NULL)     }     summarise_data <- select(       final_data,       \"location_id\",       \"sample_id\",       \"year\",       \"question\",       \"response\"     )      summarise_data <- map_df(split(       summarise_data,       summarise_data$sample_id     ), function(sample) {       # get a row to add to bottom when mean_depth calcualted       row <- sample[1, ]       row$question <- \"mean_depth\"       if (!any(sample$question %in% \"mean_depth\")) {         depths <- filter(sample, question %in% c(           \"River Depth 1\",           \"River Depth 2\",           \"River Depth 3\"         ))         if (nrow(depths) < 1) {           # some samples don't have Depths or mean_depth...so return NA           row$response <- NA         } else {           mean_depth <- mean(as.numeric(depths$response), na.rm = TRUE)            row$response <- as.character(mean_depth)         }         sample <- bind_rows(sample, row)         return(sample)       } else {         return(sample)       }     })      summarise_data <- summarise_data %>%       filter(question %in% c(         \"sand\",         \"silt_clay\",         \"boulders_cobbles\",         \"pebbles_gravel\",         \"river_width\",         \"mean_depth\"       ))     summarise_data <- tidyr::pivot_wider(summarise_data,       names_from = question,       values_from = response     )     summarise_data <- type.convert(summarise_data, as.is = TRUE)     summarise_data <- select(summarise_data, -\"sample_id\")     summarise_data <- dplyr::group_by(       summarise_data,       location_id     )     # Suppress warning because of missing values     summarise_data <- suppressWarnings(dplyr::summarise_all(       summarise_data,       ~ mean(.x, na.rm = TRUE)     ))     summarise_data$location_id <- as.character(summarise_data$location_id)     data <- left_join(data, summarise_data, by = join_by(location_id == location_id))     data <- data %>%       group_by(location_id) %>%       mutate(\"alkalinity\" = mean(alkalinity, na.rm = TRUE))     data <- ungroup(data)      data <- select(       data,       \"sample_id\",       \"location_id\",       \"date_taken\",       \"grid_reference\",       \"alkalinity\",       \"river_width\",       \"mean_depth\",       \"boulders_cobbles\",       \"pebbles_gravel\",       \"sand\",       \"silt_clay\",       # \"northing\",       # \"easting\",       \"dist_from_source\",       \"altitude\",       \"slope\",       \"grid_reference\",       \"discharge_category\"     )     whpt_input <- inner_join(output,       unique(data),       by = \"sample_id\"     )   }   whpt_input$question[whpt_input$question == \"WHPT_ASPT\"] <- \"WHPT ASPT Abund\"   whpt_input$question[whpt_input$question == \"WHPT_NTAXA\"] <- \"WHPT NTAXA Abund\"   data <- whpt_input    bias <- 1.62   analysis <- \"whpt ntaxa abund\"    names(data) <- tolower(names(data))   data <- data[!is.na(data$river_width), ]   # if no river width...return NULL   check <- FALSE   if (nrow(data) < 1) {     return(NULL)   }   # Add year  columns   data$year <- format.Date(data$date_taken, \"%Y\")   data$year <- as.integer(data$year)   rict_output <- purrr::map(unique(data$location_id), function(location_id) {    data <- data[data$location_id == location_id, ]     if (!is.null(data$river_width)) {       if (any(!is.na(data$river_width))) {         data$river_width <- as.numeric(data$river_width)         data$mean_depth <- as.numeric(data$mean_depth)         data$boulders_cobbles <- as.numeric(data$boulders_cobbles)         data$pebbles_gravel <- as.numeric(data$pebbles_gravel)         data$silt_clay <- as.numeric(data$silt_clay)         data$sand <- as.numeric(data$sand)         check <- TRUE       } else {         data <- select(           data,           -\"river_width\",           -\"mean_depth\",           -\"boulders_cobbles\",           -\"pebbles_gravel\",           -\"sand\",           -\"silt_clay\"         )       }     }     # NGR columns      data <- tidyr::separate(data,       grid_reference,       into = c(         \"NGR\",         \"NGR_EASTING\",         \"NGR_NORTHING\"       ),       sep = \" \"     )     # needs refactoring - but if no Alk results returned then add blanks/NAs     # data$alkalinity <- 75     data$sample_count <- NA     data$samples_used <- NA     data$min_date <- NA     data$max_date <- NA      data$response <- as.numeric(as.character(data$response))     data <- tidyr::pivot_wider(data,       names_from = question,       values_from = response     )     # Join to template     rict_template <- function() {       template <- data.frame(         \"LOCATION\" = character(),         \"Waterbody\" = character(),         \"YEAR\" = integer(),         \"NGR\" = character(),         \"EASTING\" = character(),         \"NORTHING\" = character(),         \"S_ALTITUDE\" = numeric(),         \"S_SLOPE\" = numeric(),         \"S_DISCHARGE_CAT\" = numeric(),         \"S_DIST_FROM_SOURCE\" = numeric(),         \"River Width (m)\" = numeric(),         \"Mean Depth (cm)\" = numeric(),         \"Alkalinity\" = numeric(),         \"% Boulders/Cobbles\" = numeric(),         \"% Pebbles/Gravel\" = numeric(),         \"% Sand\" = numeric(),         \"% Silt/Clay\" = numeric(),         \"Spr_Season_ID\" = numeric(),         \"Spr_TL2_WHPT_NTaxa (AbW,DistFam)\" = numeric(),         \"Spr_TL2_WHPT_ASPT (AbW,DistFam)\" = numeric(),         \"Sum_Season_ID\" = numeric(),         \"Sum_TL2_WHPT_NTaxa (AbW,DistFam)\" = numeric(),         \"Sum_TL2_WHPT_ASPT (AbW,DistFam)\" = numeric(),         \"Aut_Season_ID\" = numeric(),         \"Aut_TL2_WHPT_NTaxa (AbW,DistFam)\" = numeric(),         \"Aut_TL2_WHPT_ASPT (AbW,DistFam)\" = numeric(),         sample_id = character(),         check.names = check       )     }      template_nems <- rict_template()     names(template_nems) <- tolower(names(template_nems))     data$easting <- as.factor(data$NGR_EASTING)     data$northing <- as.factor(data$NGR_EASTING)     names(data) <- tolower(names(data))     data <- dplyr::bind_rows(template_nems, data)      # For each Ecology sample (survey_inv/F_BMWP_SUM) summarise     # data$location <- paste0(data$location_id, \": \", data$location_description)     data$water_body_id <- 3100     names(data) <- tolower(names(data))     data <- data.frame(data, check.names = TRUE)     names(data) <- tolower(names(data))      data$date_taken <- as.Date(data$date_taken)     data$season <- season(data$date_taken)      # summarise_data <- dplyr::group_by(     #   data,     #   location_id,     #   ngr,     #   ngr_easting,     #   ngr_northing,     #   sample_id,     #   season,     #   discharge_category,     #   water_body_id,     #   .name_repair = TRUE     # )     # Suppress warning because of missing values     # summarise_data <- suppressWarnings(dplyr::summarise_all(     #   summarise_data,     #   ~ mean(.x, na.rm = TRUE)     # ))     # Select      rict_data <- dplyr::select(data,       \"SITE\" = \"location_id\",       \"Waterbody\" = \"water_body_id\",       \"Year\" = \"year\",       \"NGR\" = \"ngr\",       \"Easting\" = \"ngr_easting\",       \"Northing\" = \"ngr_northing\",       \"Altitude\" = \"altitude\",       \"Slope\" = \"slope\",       \"Discharge\" = \"discharge_category\",       \"Dist_from_Source\" = \"dist_from_source\",       \"Mean_Width\" = \"river_width\",       \"Mean_depth\" = \"mean_depth\",       \"Alkalinity\" = \"alkalinity\",       \"Total_samples\" = \"sample_count\",       \"Samples_used\" = \"samples_used\",       \"Alk_start\" = \"min_date\",       \"Alk_end\" = \"max_date\",       \"Boulder_Cobbles\" = \"boulders_cobbles\",       \"Pebbles_Gravel\" = \"pebbles_gravel\",       \"Sand\" = \"sand\",       \"Silt_Clay\" = \"silt_clay\",       \"Spr_Season_ID\" = \"season\",       \"Spr_TL2_WHPT_NTaxa (AbW,DistFam)\" = \"whpt.ntaxa.abund\",       \"Spr_TL2_WHPT_ASPT (AbW,DistFam)\" = \"whpt.aspt.abund\",       \"Sum_Season_ID\" = \"season\",       \"Sum_TL2_WHPT_NTaxa (AbW,DistFam)\" = \"whpt.ntaxa.abund\",       \"Sum_TL2_WHPT_ASPT (AbW,DistFam)\" = \"whpt.aspt.abund\",       \"Aut_Season_ID\" = \"season\",       \"Aut_TL2_WHPT_NTaxa (AbW,DistFam)\" = \"whpt.ntaxa.abund\",       \"Aut_TL2_WHPT_ASPT (AbW,DistFam)\" = \"whpt.aspt.abund\",       \"sample_id\",       \"season\" = \"season\"     )     # Remove season not used      cols <- grep(\"Sum_|Spr_\", names(rict_data), perl = TRUE)     rict_data[rict_data$season == 3, cols] <- NA      cols <- grep(\"Spr_|Aut_\", names(rict_data), perl = TRUE)     rict_data[rict_data$season == 2, cols] <- NA      cols <- grep(\"Sum_|Aut_\", names(rict_data), perl = TRUE)     rict_data[rict_data$season == 1, cols] <- NA      # Add season id when required     rict_data$Spr_Season_ID <- 1     rict_data$Sum_Season_ID <- 2     rict_data$Aut_Season_ID <- 3     # Bias where required     rict_data$SPR_NTAXA_BIAS <- bias     rict_data$SUM_NTAXA_BIAS <- bias     rict_data$AUT_NTAXA_BIAS <- bias      rict_data$VELOCITY <- NA     rict_data$HARDNESS <- NA     rict_data$CALCIUM <- NA     rict_data$CONDUCTIVITY <- NA     # Replace NANs     is.nan.data.frame <- function(x) {       do.call(cbind, lapply(x, is.nan))     }     rict_data[is.nan(rict_data)] <- NA     # Discharge must be numeric to pass validation     rict_data$Discharge <- as.numeric(rict_data$Discharge)     rict_data <- data.frame(rict_data, check.names = FALSE)     # rict_data <- rict_data[rict_data$sample_id != \"1582198\", ]     # rict_data <- rict_data[rict_data$sample_id != \"1017980\", ]     if (nrow(rict_data) == 0) {       return(NULL)     }      rict_valid <- rict::rict_validate(rict_data, stop_if_all_fail = FALSE)     if (nrow(rict_valid$data) == 0) {       return(NULL)     }      rict_multi_year <- rict_data %>%       group_by(SITE, Year) %>%       select(\"SITE\", \"Year\", contains(\"_WHPT_\")) %>%       summarise_all(~ mean(.x, na.rm = TRUE))     predictors <- rict_data %>%       select(-\"Year\", -\"season\", -contains(\"_WHPT_\"), -\"sample_id\") %>%       unique()     multi <- inner_join(rict_multi_year, predictors, by = c(\"SITE\"))     multi <- data.frame(multi, check.names = FALSE)     multi_predict <- rict_predict(multi)     multi_predict <- select(multi_predict, \"SITE\", \"SuitCode\", \"SuitText\")     multi_predict <- unique(multi_predict)     multi_class <- rict::rict(multi, year_type = \"multi\")     multi_class <- inner_join(multi_class, multi_predict, by = join_by(SITE))     multi_year_ntaxa <- select(       multi_class,       \"SITE\",       \"H\" = \"H_NTAXA_spr_aut\",       \"G\" = \"G_NTAXA_spr_aut\",       \"M\" = \"M_NTAXA_spr_aut\",       \"P\" = \"P_NTAXA_spr_aut\",       \"B\" = \"B_NTAXA_spr_aut\",       \"Class\" = \"mostProb_NTAXA_spr_aut\",       \"EQR\" = \"NTAXA_aver_spr_aut\",       \"Suit Code\" = \"SuitCode\",       \"Suit Text\" = \"SuitText\"     )     multi_year_ntaxa$parameter <- \"Macroinvertebrates (NTAXA)\"     multi_year_aspt <- select(       multi_class,       \"SITE\",       \"H\" = \"H_ASPT_spr_aut\",       \"G\" = \"G_ASPT_spr_aut\",       \"M\" = \"M_ASPT_spr_aut\",       \"P\" = \"P_ASPT_spr_aut\",       \"B\" = \"B_ASPT_spr_aut\",       \"Class\" = \"mostProb_ASPT_spr_aut\",       \"EQR\" = \"ASPT_aver_spr_aut\",       \"Suit Code\" = \"SuitCode\",       \"Suit Text\" = \"SuitText\"     )      multi_year_aspt$parameter <- \"Macroinvertebrates (ASPT)\"     multi_year_output <- bind_rows(       multi_year_aspt,       multi_year_ntaxa     )     multi_year_output <- multi_year_output[complete.cases(multi_year_output), ]     multi_year_output <- mutate_all(multi_year_output, as.character)     multi_year_output <- pivot_longer(multi_year_output,       names_to = \"question\",       values_to = \"response\",       cols = c(-parameter, -SITE)     )     # rict_class <- inner_join(rict_class,     #                          rict_data[, c(\"SITE\",\"sample_id\")],     #                          by = \"sample_id\")     multi_year_output <-       rename(multi_year_output, \"location_id\" = SITE)      predict_single <- rict::rict_predict(rict_data, all_indices = TRUE)     # predict_single$sample_id <- rict_data$sample_id          sample_season <- select(data, \"location_id\", \"sample_id\", \"season\")     sample_season <- unique(sample_season)     sample_season$season <- as.numeric(sample_season$season)     predict_single <- select(predict_single,                              \"SuitCode\", \"SuitText\",                              \"SEASON\", \"SITE\",                              \"TL2_08_Group_ARMI_Score\",                              \"TL2_08_Group_ARMI_NTaxa\",                              \"TL2_WHPT_Score_AbW_DistFam\",                              \"TL2_WHPT_NTAXA_AbW_DistFam\",                               \"TL2_WHPT_ASPT_AbW_DistFam\")     predict_single <- unique(predict_single)     predict_single <- inner_join(sample_season,                                   predict_single,                                   by = join_by(season == SEASON,                                               location_id == SITE))      single_predict <- predict_single     # single_predict <- select(predict_single, sample_id, SuitCode, SuitText)     # single_predict <- unique(single_predict)     rict_output <- rict::rict(rict_data, year_type = \"single\")     rict_output$sample_id <- rict_data$sample_id     rict_output <- unique(rict_output)      rict_output <- rict_output[rict_output$sample_id %in% single_predict$sample_id, ]     rict_data <- unique(rict_data)      rict_output <- inner_join(rict_output, single_predict, by = join_by(sample_id))      spr_ntaxa <- select(       rict_output,       \"sample_id\",       \"H\" = \"H_NTAXA_spr\",       \"G\" = \"G_NTAXA_spr\",       \"M\" = \"M_NTAXA_spr\",       \"P\" = \"P_NTAXA_spr\",       \"B\" = \"B_NTAXA_spr\",       \"Class\" = \"mostProb_NTAXA_spr\",       \"EQR\" = \"NTAXA_eqr_av_spr\",       \"Suit Code\" = \"SuitCode\",       \"Suit Text\" = \"SuitText\"     )     spr_ntaxa$parameter <- \"Macroinvertebrates (NTAXA)\"      sum_ntaxa <- select(       rict_output,       \"sample_id\",       \"H\" = \"H_NTAXA_sum\",       \"G\" = \"G_NTAXA_sum\",       \"M\" = \"M_NTAXA_sum\",       \"P\" = \"P_NTAXA_sum\",       \"B\" = \"B_NTAXA_sum\",       \"Class\" = \"mostProb_NTAXA_sum\",       \"EQR\" = \"NTAXA_eqr_av_sum\",       \"Suit Code\" = \"SuitCode\",       \"Suit Text\" = \"SuitText\"     )     sum_ntaxa$parameter <- \"Macroinvertebrates (NTAXA)\"      aut_ntaxa <- select(       rict_output,       \"sample_id\",       \"H\" = \"H_NTAXA_aut\",       \"G\" = \"G_NTAXA_aut\",       \"M\" = \"M_NTAXA_aut\",       \"P\" = \"P_NTAXA_aut\",       \"B\" = \"B_NTAXA_aut\",       \"Class\" = \"mostProb_NTAXA_aut\",       \"EQR\" = \"NTAXA_eqr_av_aut\",       \"Suit Code\" = \"SuitCode\",       \"Suit Text\" = \"SuitText\"     )     aut_ntaxa$parameter <- \"Macroinvertebrates (NTAXA)\"      aut_aspt <- select(       rict_output,       \"sample_id\",       \"H\" = \"H_ASPT_aut\",       \"G\" = \"G_ASPT_aut\",       \"M\" = \"M_ASPT_aut\",       \"P\" = \"P_ASPT_aut\",       \"B\" = \"B_ASPT_aut\",       \"Class\" = \"mostProb_ASPT_aut\",       \"EQR\" = \"ASPT_eqr_av_aut\",       \"Suit Code\" = \"SuitCode\",       \"Suit Text\" = \"SuitText\"     )     aut_aspt$parameter <- \"Macroinvertebrates (ASPT)\"      spr_aspt <- select(       rict_output,       \"sample_id\",       \"H\" = \"H_ASPT_spr\",       \"G\" = \"G_ASPT_spr\",       \"M\" = \"M_ASPT_spr\",       \"P\" = \"P_ASPT_spr\",       \"B\" = \"B_ASPT_spr\",       \"Class\" = \"mostProb_ASPT_spr\",       \"EQR\" = \"ASPT_eqr_av_spr\",       \"Suit Code\" = \"SuitCode\",       \"Suit Text\" = \"SuitText\"     )     spr_aspt$parameter <- \"Macroinvertebrates (ASPT)\"      sum_aspt <- select(       rict_output,       \"sample_id\",       \"H\" = \"H_ASPT_sum\",       \"G\" = \"G_ASPT_sum\",       \"M\" = \"M_ASPT_sum\",       \"P\" = \"P_ASPT_sum\",       \"B\" = \"B_ASPT_sum\",       \"Class\" = \"mostProb_ASPT_sum\",       \"EQR\" = \"eqr_av_sum_aspt\",       \"Suit Code\" = \"SuitCode\",       \"Suit Text\" = \"SuitText\"     )     sum_aspt$parameter <- \"Macroinvertebrates (ASPT)\"     rict_class <- bind_rows(       spr_aspt,       sum_aspt,       aut_aspt,       spr_ntaxa,       sum_ntaxa,       aut_ntaxa     )      rict_class <- rict_class[complete.cases(rict_class), ]     rict_class <- mutate_all(rict_class, as.character)     rict_class <- pivot_longer(rict_class,       names_to = \"question\",       values_to = \"response\",       cols = c(-sample_id, -parameter)     )     rict_class <- inner_join(rict_class,       rict_data[, c(\"SITE\", \"sample_id\")],       by = \"sample_id\",       relationship = \"many-to-many\"     )     rict_class <- rename(rict_class, \"location_id\" = SITE)     rict_aspt <- tibble(       \"location_id\" = predict_single$location_id,       \"sample_id\" = rict_data$sample_id,       \"question\" = \"RICT Reference WHPT ASPT\",       \"response\" = as.character(predict_single$TL2_WHPT_ASPT_AbW_DistFam)     )     rict_ntaxa <- tibble(       \"location_id\" = predict_single$location_id,       \"sample_id\" = rict_data$sample_id,       \"question\" = \"RICT Rerference WHPT NTAXA\",       \"response\" = as.character(predict_single$TL2_WHPT_NTAXA_AbW_DistFam)     )     rict_river_score <- tibble(       \"location_id\" = predict_single$location_id,       \"sample_id\" = rict_data$sample_id,       \"question\" = \"RICT Rerference ARMI Score\",       \"response\" = as.character(predict_single$TL2_08_Group_ARMI_Score)     )       rict_river_ntaxa <- tibble(       \"location_id\" = predict_single$location_id,       \"sample_id\" = rict_data$sample_id,       \"question\" = \"RICT Rerference ARMI NTAXA\",       \"response\" = as.character(predict_single$TL2_08_Group_ARMI_NTaxa)     )          predict_single <- bind_rows(rict_aspt, rict_ntaxa, rict_river_score, rict_river_ntaxa)     predict_single$parameter <- \"RICT Prediction\"     rict_prediction <- bind_rows(       predict_single,       rict_class,       multi_year_output     )     # create row for years included in multi-year     row <- rict_prediction[is.na(rict_prediction$sample_id), ]     row <- row[1:2, ]     row$parameter[1] <- \"Macroinvertebrates (ASPT)\"     row$parameter[2] <- \"Macroinvertebrates (NTAXA)\"     row$question <- \"Years included\"     row$response <- paste(unique(rict_data$Year), collapse = \",\")     rict_prediction <- bind_rows(rict_prediction, row)   })    output <- bind_rows(rict_output)   if (nrow(output) < 1) {     return(NULL)   }   output <- unique(output)   output <- mutate(output,     question = ifelse(question == \"M\",       \"CoCM\",       question     ),     question = ifelse(question == \"P\",       \"CoCP\",       question     ),     question = ifelse(question == \"B\",       \"CoCB\",       question     ),     question = ifelse(question == \"H\",       \"CoCH\",       question     ),     question = ifelse(question == \"G\",       \"CoCG\",       question     )   )     output <- mutate(output,     response = ifelse(response == \"H\",       \"High\",       response     ),     response = ifelse(response == \"G\",       \"Good\",       response     ),     response = ifelse(response == \"M\",       \"Moderate\",       response     ),     response = ifelse(response == \"P\",       \"Poor\",       response     ),     response = ifelse(response == \"B\",       \"Bad\",       response     )   )    return(output) }"},{"path":"https://ecodata1.github.io/hera/articles/rict.html","id":"outcome","dir":"Articles","previous_headings":"","what":"Outcome","title":"RICT","text":"outcome assessment.","code":""},{"path":"https://ecodata1.github.io/hera/articles/rict.html","id":"check","dir":"Articles","previous_headings":"","what":"Check","title":"RICT","text":"Run checks assessment.","code":"#> Test passed  #> Test passed"},{"path":"https://ecodata1.github.io/hera/articles/rict.html","id":"update","dir":"Articles","previous_headings":"","what":"Update","title":"RICT","text":"Update catalogue assessments make available. updating catalogue, rebuild package, click Build > Install Restart menu ‘Install Restart’ button Build pane.","code":"#> ✔ Setting active project to '/home/runner/work/hera/hera' #> ✔ Saving 'catalogue' to 'data/catalogue.rda' #> • Document your data (see 'https://r-pkgs.org/data.html')"},{"path":"https://ecodata1.github.io/hera/articles/rict.html","id":"test","dir":"Articles","previous_headings":"","what":"Test","title":"RICT","text":"section tests assessment usable using assessment function.","code":"#> Hello from hera, ...work in progress! #> Hello from hera, ...work in progress! #> 8175 #> Variables for the 'physical' model detected - applying relevant checks. #> Grid reference values detected for 'GB' - applying relevant checks. #> Success, all validation checks passed! #> Variables for the 'physical' model detected - applying relevant checks. #> Grid reference values detected for 'GB' - applying relevant checks. #> Success, all validation checks passed! #> Variables for the 'physical' model detected - applying relevant checks. #> Grid reference values detected for 'GB' - applying relevant checks. #> Success, all validation checks passed! #> Classifying... #> Variables for the 'physical' model detected - applying relevant checks. #> Grid reference values detected for 'GB' - applying relevant checks. #> Success, all validation checks passed! #> Warning in data.frame(..., check.names = FALSE): row names were found from a #> short variable and have been discarded #> Variables for the 'physical' model detected - applying relevant checks. #> Grid reference values detected for 'GB' - applying relevant checks. #> Success, all validation checks passed! #> Classifying..."},{"path":"https://ecodata1.github.io/hera/articles/rict.html","id":"launch-app","dir":"Articles","previous_headings":"","what":"Launch app","title":"RICT","text":"interactive application displaying results assessment.","code":""},{"path":"https://ecodata1.github.io/hera/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tim Foster. Author, maintainer.","code":""},{"path":"https://ecodata1.github.io/hera/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Foster T (2023). hera: Building Environmental Models Together. R package version 0.2.0, https://github.com/ecodata1/hera, https://ecodata1.github.io/hera.","code":"@Manual{,   title = {hera: Building Environmental Models Together},   author = {Tim Foster},   year = {2023},   note = {R package version 0.2.0, https://github.com/ecodata1/hera},   url = {https://ecodata1.github.io/hera}, }"},{"path":"https://ecodata1.github.io/hera/index.html","id":"hera","dir":"","previous_headings":"","what":"Building Environmental Models Together","title":"Building Environmental Models Together","text":"WORK PROGRESS Hera prototype package explore future regulatory environmental modelling. package outlines possible approaches creating shared research platform building, testing deploying models used assess environmental risk regulatory purposes. See Request comment paper outline broad technical specifications. Hera envisaged opinionated collections R packages designed sharing environmental models. packages share underlying design, grammar data structures. allows separation concerns data, models, post-modelling steps visualisation. Allowing greater collaboration sharing methods tools.","code":""},{"path":"https://ecodata1.github.io/hera/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Building Environmental Models Together","text":"Install development version GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"ecodata1/hera\")"},{"path":"https://ecodata1.github.io/hera/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Building Environmental Models Together","text":"Read white paper article documentation website (work progress)","code":""},{"path":"https://ecodata1.github.io/hera/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Building Environmental Models Together","text":"Assess demo data various environmental risks: Alternatively, can view catalogue select assessments run. select assessment(s) wish run name:","code":"library(hera) data <- assess(hera::demo_data) data[1:5, c(\"sample_id\", \"parameter\", \"question\", \"response\")] #> # A tibble: 5 × 4 #>   sample_id parameter question           response                          #>   <chr>     <chr>     <chr>              <chr>                             #> 1 1017980   <NA>      EPSI Score TL2     97.2877525074163                  #> 2 1017980   <NA>      EPSI Condition TL2 Minimally sedimented/unsedimented #> 3 1101214   <NA>      EPSI Score TL2     94.6979865771812                  #> 4 1101214   <NA>      EPSI Condition TL2 Minimally sedimented/unsedimented #> 5 1250462   <NA>      EPSI Score TL2     97.8168378529374 catalogue #> # A tibble: 4 × 3 #>   assessment                data               assessment_function #>   <chr>                     <list>             <list>              #> 1 Macroinvertebrate Metrics <tibble [11 × 10]> <fn>                #> 2 DARLEQ3                   <tibble [35 × 12]> <fn>                #> 3 Bankside Consistency      <tibble [11 × 12]> <fn>                #> 4 RICT                      <tibble [20 × 12]> <fn> assessments <- assess(demo_data,                        name = c(\"RICT\",                                \"Macroinvertebrate Metrics\")) assessments[1:5, c(\"sample_id\", \"parameter\", \"question\", \"response\")] #> # A tibble: 5 × 4 #>   sample_id parameter question           response                          #>   <chr>     <chr>     <chr>              <chr>                             #> 1 1017980   <NA>      EPSI Score TL2     97.2877525074163                  #> 2 1017980   <NA>      EPSI Condition TL2 Minimally sedimented/unsedimented #> 3 1101214   <NA>      EPSI Score TL2     94.6979865771812                  #> 4 1101214   <NA>      EPSI Condition TL2 Minimally sedimented/unsedimented #> 5 1250462   <NA>      EPSI Score TL2     97.8168378529374"},{"path":"https://ecodata1.github.io/hera/reference/assess.html","id":null,"dir":"Reference","previous_headings":"","what":"Assess — assess","title":"Assess — assess","text":"Run assessment","code":""},{"path":"https://ecodata1.github.io/hera/reference/assess.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assess — assess","text":"","code":"assess(data = NULL, name = NULL, catalogue = NULL)"},{"path":"https://ecodata1.github.io/hera/reference/assess.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assess — assess","text":"data Dataframe variables hera inter-change format name Name assessment used catalogue Dataframe model_dataframe see `catalogue`","code":""},{"path":"https://ecodata1.github.io/hera/reference/assess.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assess — assess","text":"Dataframe assessments","code":""},{"path":"https://ecodata1.github.io/hera/reference/assess.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Assess — assess","text":"assess() assess","code":""},{"path":"https://ecodata1.github.io/hera/reference/assess.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assess — assess","text":"","code":"if (FALSE) { assessments <- assess(hera::demo_data) }"},{"path":"https://ecodata1.github.io/hera/reference/catalogue.html","id":null,"dir":"Reference","previous_headings":"","what":"Catalogue of assessments — catalogue","title":"Catalogue of assessments — catalogue","text":"data frame containing descriptions, data functions used assessment methods. catalogue automatically extended knitting new assessment vignettes rebuilding package. See Development Guide package website.","code":""},{"path":"https://ecodata1.github.io/hera/reference/catalogue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Catalogue of assessments — catalogue","text":"","code":"catalogue"},{"path":"https://ecodata1.github.io/hera/reference/catalogue.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Catalogue of assessments — catalogue","text":"data frame 3 variables: assessment Name assessment data List data frame describing input output data   assessment assessment_function Assessment function generates calculated   output values","code":""},{"path":"https://ecodata1.github.io/hera/reference/catalogue.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Catalogue of assessments — catalogue","text":"See assessment detailed references.","code":""},{"path":"https://ecodata1.github.io/hera/reference/combine.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine — combine","title":"Combine — combine","text":"Output columns data relevant assessment name. Either sample_id location_id (depending output calculated)","code":""},{"path":"https://ecodata1.github.io/hera/reference/combine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine — combine","text":"","code":"combine(outcome, data)"},{"path":"https://ecodata1.github.io/hera/reference/combine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine — combine","text":"outcome output prediction hera function data input data prediction hera function","code":""},{"path":"https://ecodata1.github.io/hera/reference/convert.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert — convert","title":"Convert — convert","text":"Convert input data internal `hera` structure. allows data different sources used input.","code":""},{"path":"https://ecodata1.github.io/hera/reference/convert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert — convert","text":"","code":"convert(data, convert_to = \"hera\", convert_from = \"sepa_lims\")"},{"path":"https://ecodata1.github.io/hera/reference/convert.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert — convert","text":"data Data raw input number sources convert_to Convert data `hera` format default. Currently, reverse convert back original input format possible. convert_from Specify structure input data. can 'sepa' 'sepa_lims'. 'sepa' internal, historic reportable analysis results structure, 'lims' new results structure direct lab info system.","code":""},{"path":"https://ecodata1.github.io/hera/reference/convert.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert — convert","text":"Dataframe `hera` structure. See `demo_data`","code":""},{"path":"https://ecodata1.github.io/hera/reference/convert.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert — convert","text":"","code":"data <-   read.csv(system.file(\"extdat\",     \"demo-data/analysis-results-ecology.csv\",     package = \"hera\"   ), check.names = FALSE)  r <- convert(data, convert_from = \"sepa\")"},{"path":"https://ecodata1.github.io/hera/reference/demo_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset of WFD data interchange format — demo_data","title":"Example dataset of WFD data interchange format — demo_data","text":"dataset containing ecology chemistry data","code":""},{"path":"https://ecodata1.github.io/hera/reference/demo_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset of WFD data interchange format — demo_data","text":"","code":"demo_data"},{"path":"https://ecodata1.github.io/hera/reference/demo_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset of WFD data interchange format — demo_data","text":"data frame 8477 rows 24 variables: location_id Location ID location_description Location description easting Easting northing northing latitude Latitude longitude longitude date_taken Date taken sample_id sample ID analysis_name Name analysis question question response response units units mean_alkalinity mean alkalinity result_id result ID grid_reference Grid Reference standard standard quality_element quality element water_body_id water body id label label dist_from_source distance source slope slope source_altitude source altitude parameter parameter","code":""},{"path":"https://ecodata1.github.io/hera/reference/demo_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset of WFD data interchange format — demo_data","text":"Agency sampling data","code":""},{"path":"https://ecodata1.github.io/hera/reference/get_bulk_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Environment Agency demo data — get_bulk_data","title":"Get Environment Agency demo data — get_bulk_data","text":"Get Environment Agency demo data","code":""},{"path":"https://ecodata1.github.io/hera/reference/get_bulk_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Environment Agency demo data — get_bulk_data","text":"","code":"get_bulk_data()"},{"path":"https://ecodata1.github.io/hera/reference/get_bulk_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Environment Agency demo data — get_bulk_data","text":"dataframe demo data testing","code":""},{"path":"https://ecodata1.github.io/hera/reference/get_bulk_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Environment Agency demo data — get_bulk_data","text":"","code":"if (FALSE) { data <- get_demo_data() }"},{"path":"https://ecodata1.github.io/hera/reference/get_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Get data — get_data","title":"Get data — get_data","text":"Import data web services convert standard format `hera` regulatory assessment tool.","code":""},{"path":"https://ecodata1.github.io/hera/reference/get_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get data — get_data","text":"","code":"get_data(   location_id = NULL,   take = 10000,   date_from = NULL,   date_to = NULL,   dataset = \"analytical_results\",   year = NULL,   water_body_id = \"\",   source = \"sepa\" )"},{"path":"https://ecodata1.github.io/hera/reference/get_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get data — get_data","text":"location_id Unique ID location. take Number observation download. \"ea\" API services. date_from Start date taken window string format: \"2013-12-31\". date_to End date taken window string format: \"2015-12-31\". dataset Default get Ecology monitoring data, set \"replocs\" represent location data SEPA year Classification year water_body_id Water body ID used replocs table queries. source data source, either \"ea\" \"sepa\". SEPA internal access .","code":""},{"path":"https://ecodata1.github.io/hera/reference/get_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get data — get_data","text":"Data frame","code":""},{"path":"https://ecodata1.github.io/hera/reference/get_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get data — get_data","text":"","code":"if (FALSE) { data <- get_data(location_id = 1000, source = \"ea\") class <- assessment(data) }"},{"path":"https://ecodata1.github.io/hera/reference/launch_app.html","id":null,"dir":"Reference","previous_headings":"","what":"Launch hera app — launch_app","title":"Launch hera app — launch_app","text":"Launches hera shiny app optional data `catalogue`.","code":""},{"path":"https://ecodata1.github.io/hera/reference/launch_app.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Launch hera app — launch_app","text":"","code":"launch_app(new_catalogue = NULL, data = NULL)"},{"path":"https://ecodata1.github.io/hera/reference/launch_app.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Launch hera app — launch_app","text":"new_catalogue Dataframe catalogue see `catalogue` data Dataframe variables WFD inter-change format","code":""},{"path":"https://ecodata1.github.io/hera/reference/launch_app.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Launch hera app — launch_app","text":"Shiny app","code":""},{"path":"https://ecodata1.github.io/hera/reference/launch_app.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Launch hera app — launch_app","text":"","code":"if (FALSE) { launch_app() }"},{"path":"https://ecodata1.github.io/hera/reference/lims_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Example dataset of raw LIMS data — lims_data","title":"Example dataset of raw LIMS data — lims_data","text":"Example dataset raw LIMS data","code":""},{"path":"https://ecodata1.github.io/hera/reference/lims_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example dataset of raw LIMS data — lims_data","text":"","code":"lims_data"},{"path":"https://ecodata1.github.io/hera/reference/lims_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example dataset of raw LIMS data — lims_data","text":"data frame 42 rows 16 variables: ORIGINAL_SAMPLE ORIGINAL_SAMPLE ID SAMPLE_NUMBER SAMPLE_NUMBER SAMPLING_POINT SAMPLING_POINT DESCRIPTION DESCRIPTION STATUS STATUS LOCATION LOCATION ANALYSIS ANALYSIS REPORTED_NAME REPORTED_NAME FORMATTED_ENTRY FORMATTED_ENTRY UNITS UNITS SAMPLED_DATE SAMPLED_DATE TEMPLATE TEMPLATE SAMPLED_BY SAMPLED_BY REPORTABLE REPORTABLE FORMULATION FORMULATION TEST_NUMBER TEST_NUMBER","code":""},{"path":"https://ecodata1.github.io/hera/reference/lims_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example dataset of raw LIMS data — lims_data","text":"Agency sampling data","code":""},{"path":"https://ecodata1.github.io/hera/reference/questions.html","id":null,"dir":"Reference","previous_headings":"","what":"Questions — questions","title":"Questions — questions","text":"Return list questions assessments catalogue","code":""},{"path":"https://ecodata1.github.io/hera/reference/questions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Questions — questions","text":"","code":"questions()"},{"path":"https://ecodata1.github.io/hera/reference/questions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Questions — questions","text":"dataframe","code":""},{"path":"https://ecodata1.github.io/hera/reference/questions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Questions — questions","text":"","code":"questions <- questions()"},{"path":"https://ecodata1.github.io/hera/reference/season.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Season from Date — season","title":"Calculate Season from Date — season","text":"Calculate Season Date","code":""},{"path":"https://ecodata1.github.io/hera/reference/season.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Season from Date — season","text":"","code":"season(   dates,   winter = \"2012-12-1\",   spring = \"2012-3-1\",   summer = \"2012-6-1\",   autumn = \"2012-9-1\",   output = \"numeric\" )"},{"path":"https://ecodata1.github.io/hera/reference/season.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Season from Date — season","text":"dates List dates class Date winter Winter's start date spring Spring's start date summer Summer's start date autumn Autumn's start date output Options: numeric, shortname, fullname","code":""},{"path":"https://ecodata1.github.io/hera/reference/season.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Season from Date — season","text":"List seasons numbers based seasons required RICT. Broadly sampling 'seasons' used routine sampling","code":""},{"path":"https://ecodata1.github.io/hera/reference/season.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Season from Date — season","text":"","code":"if (FALSE) { season <- season(Sys.Date()) }"},{"path":"https://ecodata1.github.io/hera/reference/survey_import.html","id":null,"dir":"Reference","previous_headings":"","what":"Import Survey Template — survey_import","title":"Import Survey Template — survey_import","text":"Import Survey Template","code":""},{"path":"https://ecodata1.github.io/hera/reference/survey_import.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import Survey Template — survey_import","text":"","code":"survey_import(path = NULL)"},{"path":"https://ecodata1.github.io/hera/reference/survey_import.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import Survey Template — survey_import","text":"path character file path survey template","code":""},{"path":"https://ecodata1.github.io/hera/reference/survey_import.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import Survey Template — survey_import","text":"Data frame 5 variables project_id character project id sample_id character sample id question question - character question response response - character response value label label - Mainly used labelling taxonomic observations","code":""},{"path":"https://ecodata1.github.io/hera/reference/survey_import.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import Survey Template — survey_import","text":"","code":"if (FALSE) { file <- system.file(\"extdat\",   \"survey-template/220421-SelfMon-N4952-CAV1-Enhanced.xlsx\",   package =     \"aquaman\" ) data <- survey_import(file) }"},{"path":"https://ecodata1.github.io/hera/reference/validation.html","id":null,"dir":"Reference","previous_headings":"","what":"Validation — validation","title":"Validation — validation","text":"Validation input data.","code":""},{"path":"https://ecodata1.github.io/hera/reference/validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validation — validation","text":"","code":"validation(data = NULL)"},{"path":"https://ecodata1.github.io/hera/reference/validation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validation — validation","text":"data Dataframe variables WFD inter-change format","code":""},{"path":"https://ecodata1.github.io/hera/reference/validation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validation — validation","text":"Dataframe validation messages","code":""},{"path":"https://ecodata1.github.io/hera/reference/validation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validation — validation","text":"validation() Validation","code":""},{"path":"https://ecodata1.github.io/hera/reference/validation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validation — validation","text":"","code":"validations <- validation(demo_data) #> Hello from hera, ...work in progress! #> Warning: GDAL Message 1: +init=epsg:XXXX syntax is deprecated. It might return a CRS with a non-EPSG compliant axis order."}]
